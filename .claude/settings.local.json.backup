{
  "permissions": {
    "allow": [
      "Bash(chmod:*)",
      "Bash(ls:*)",
      "Bash(diff:*)",
      "Bash(cp:*)",
      "Bash(git check-ignore:*)",
      "Bash(git branch:*)",
      "Bash(psql:*)",
      "Bash(python:*)",
      "Bash(grep:*)",
      "Bash(find:*)",
      "Bash(docker exec:*)",
      "Bash(./backups/backup_database.sh:*)",
      "Bash(mkdir:*)",
      "Bash(mv:*)",
      "Bash(cat:*)",
      "Bash(sed:*)",
      "Bash(git commit:*)",
      "Bash(git add:*)",
      "Bash(git push:*)",
      "Bash(ssh:*)",
      "Bash(./scripts/simple-deploy-mcp.sh:*)",
      "Bash(rg:*)",
      "Bash(rm:*)",
      "Bash(curl:*)",
      "Bash(pdftotext:*)",
      "Bash(PYTHONPATH=/home/chris/proethica python scripts/sync_ontology_to_database.py --domain bfo)",
      "Bash(PYTHONPATH=/home/chris/proethica python scripts/sync_ontology_to_database.py --domain engineering-ethics --ttl-path ontologies/engineering-ethics.ttl)",
      "Bash(PYTHONPATH=/home/chris/proethica python -c \"\nfrom mcp.http_ontology_mcp_server import OntologyMCPServer\nimport os\nprint(''MCP Server Ontology Configuration Test'')\nprint(''='' * 50)\nprint(f''ONTOLOGY_DIR: {os.environ.get(\"\"ONTOLOGY_DIR\"\", \"\"default\"\")}'')\nserver = OntologyMCPServer()\ngraph = server._load_graph_from_file(''proethica-intermediate'')\nprint(f''Loaded {len(graph)} triples from proethica-intermediate ontology'')\nprint(''‚úÖ MCP server ontology loading works correctly'')\n\")",
      "Bash(PYTHONPATH=/home/chris/proethica python scripts/sync_ontology_to_database.py)",
      "Bash(PYTHONPATH=/home/chris/proethica python scripts/sync_ontology_to_database.py engineering-ethics)",
      "Bash(PYTHONPATH=/home/chris/proethica python scripts/sync_ontology_to_database.py --domain engineering-ethics)",
      "Bash(PYTHONPATH=/home/chris/proethica python -c \"\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\nos.environ['SQLALCHEMY_DATABASE_URI'] = os.environ.get('DATABASE_URL', 'postgresql://postgres:PASS@localhost:5433/ai_ethical_dm')\n\nfrom app import create_app, db\nfrom app.models.world import World\nfrom app.services.ontology_entity_service import OntologyEntityService\n\napp = create_app()\nwith app.app_context():\n    world = World.query.get(1)\n    if world:\n        service = OntologyEntityService.get_instance()\n        # Clear cache first\n        service.invalidate_cache()\n        entities = service.get_entities_for_world(world)\n        \n        print(f'World: {world.name}')\n        print(f'Ontology ID: {world.ontology_id}')\n        \n        if 'entities' in entities:\n            for entity_type, entity_list in entities['entities'].items():\n                print(f'{entity_type.title()}: {len(entity_list)} entities')\n                if entity_type in ['principle', 'obligation'] and len(entity_list) > 0:\n                    print(f'  First few {entity_type}s:')\n                    for i, entity in enumerate(entity_list[:3]):\n                        print(f'    - {entity[\\\"label\\\"]}')\n        else:\n            print('No entities found')\n    else:\n        print('World 1 not found')\n\")",
      "Bash(/home/chris/.npm-global/lib/node_modules/@anthropic-ai/claude-code/vendor/ripgrep/x64-linux/rg -i -n \"case.?stud(y|ies)\" /home/chris/proethica)",
      "Bash(bash:*)",
      "Bash(./backup_database.sh:*)",
      "Bash(touch:*)",
      "WebFetch(domain:localhost)",
      "Bash(SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python3 -c \"\nfrom app import create_app\nfrom app.models import db\nimport os\n\napp = create_app()\nwith app.app_context():\n    # Get all table names\n    inspector = db.inspect(db.engine)\n    tables = inspector.get_table_names()\n    print('Current database tables:')\n    for table in sorted(tables):\n        print(f'  - {table}')\n        \n    print('\\nKey tables for type mapping:')\n    key_tables = ['guidelines', 'entity_triples', 'documents']\n    for table in key_tables:\n        if table in tables:\n            print(f'\\n=== {table.upper()} ===')\n            columns = inspector.get_columns(table)\n            for col in columns:\n                nullable = 'NULL' if col['nullable'] else 'NOT NULL'\n                default = f' DEFAULT {col[\\\"default\\\"]}' if col.get('default') else ''\n                print(f'  {col[\\\"name\\\"]:<25} {str(col[\\\"type\\\"]):<20} {nullable}{default}')\n\")",
      "Bash(git tag:*)",
      "Bash(./mcp/deployment/quick-deploy-mcp.sh:*)",
      "Bash(./mcp/deployment/check-mcp-health.sh:*)",
      "Bash(./run/run_generate_ontology_term_links.sh:*)",
      "Bash(source:*)",
      "Bash(PGPASSWORD=PASS psql:*)",
      "Bash(kill:*)",
      "Bash(pkill:*)",
      "Bash(# Move domain-generic tests to utils/test/\nmv test_enhanced_schema.py utils/test/ 2>/dev/null || echo \"Already moved\"\nmv test_type_mapping_database.py utils/test/ 2>/dev/null || echo \"Already moved\"\nmv test_mcp_field_mapping_fix.py utils/test/ 2>/dev/null || echo \"Already moved\"\nmv test_real_mcp_scenario.py utils/test/ 2>/dev/null || echo \"Already moved\"\nmv test_association_service.py utils/test/ 2>/dev/null || echo \"Already moved\"\nmv test_document_19.py utils/test/ 2>/dev/null || echo \"Already moved\"\nmv test_concept_remapping.py utils/test/ 2>/dev/null || echo \"Already moved\"\nmv test_existing_data_migration.py utils/test/ 2>/dev/null || echo \"Already moved\")",
      "Bash(# Move domain-specific tests to utils/other/\nmv test_adapter_simple.py utils/other/ 2>/dev/null || echo \"Already moved\"\nmv test_real_case_deconstruction.py utils/other/ 2>/dev/null || echo \"Already moved\"\nmv test_scenario_generation.py utils/other/ 2>/dev/null || echo \"Already moved\"\nmv test_ontology_entity_matching.py utils/other/ 2>/dev/null || echo \"Already moved\")",
      "Bash(# Move UI-related docs\nmv UI_REFRESH_IMPLEMENTATION.md docs/ui/ 2>/dev/null || echo \"Already moved\"\nmv UI_REFRESH_PLAN.md docs/ui/ 2>/dev/null || echo \"Already moved\")",
      "Bash(# Move type management docs (domain-specific but important for reference)\nmv TYPE_MANAGEMENT_OPTIMIZATION_2025_06_09.md docs/reference/ 2>/dev/null || echo \"Already moved\"\nmv TYPE_MANAGEMENT_REVIEW_GUIDE.md docs/reference/ 2>/dev/null || echo \"Already moved\")",
      "Bash(# Move project management docs\nmv CLEANUP_SUMMARY.md docs/project-management/ 2>/dev/null || echo \"Already moved\")",
      "Bash(# HOW_TO_START.md stays in docs root as it's a core getting started guide\nmv HOW_TO_START.md docs/ 2>/dev/null || echo \"Already moved\")",
      "Bash(# Move generic infrastructure SQL\nmv /home/chris/proethica/init-pgvector.sql /home/chris/proethica/utils/sql/)",
      "Bash(# Move domain-specific maintenance SQL\nmv /home/chris/proethica/cleanup_orphaned_guidelines.sql /home/chris/proethica/utils/sql/maintenance/\nmv /home/chris/proethica/cleanup_orphaned_triples.sql /home/chris/proethica/utils/sql/maintenance/\nmv /home/chris/proethica/create_missing_guideline_tables.sql /home/chris/proethica/utils/sql/maintenance/)",
      "Bash(# Create directories for different types of utilities\nmkdir -p /home/chris/proethica/utils/database /home/chris/proethica/utils/debugging /home/chris/proethica/utils/migration)",
      "Bash(# Move database setup/creation scripts\nmv /home/chris/proethica/create_deconstruction_tables.py /home/chris/proethica/utils/database/\nmv /home/chris/proethica/create_test_data.py /home/chris/proethica/utils/database/\n\n# Move debugging/examination scripts\nmv /home/chris/proethica/debug_association_error.py /home/chris/proethica/utils/debugging/\nmv /home/chris/proethica/examine_detailed_data.py /home/chris/proethica/utils/debugging/\nmv /home/chris/proethica/examine_guideline_data.py /home/chris/proethica/utils/debugging/\nmv /home/chris/proethica/simple_cleanup_check.py /home/chris/proethica/utils/debugging/\nmv /home/chris/proethica/demo_enhanced_schema.py /home/chris/proethica/utils/debugging/\nmv /home/chris/proethica/simple_test.py /home/chris/proethica/utils/debugging/\nmv /home/chris/proethica/quick_type_test.py /home/chris/proethica/utils/debugging/\n\n# Move migration/update scripts\nmv /home/chris/proethica/add_entity_type_to_term_links.py /home/chris/proethica/utils/migration/\nmv /home/chris/proethica/fix_unmapped_concept_types.py /home/chris/proethica/utils/migration/\nmv /home/chris/proethica/run_type_mapping_migrations.py /home/chris/proethica/utils/migration/\nmv /home/chris/proethica/update_pending_concept_mappings.py /home/chris/proethica/utils/migration/\nmv /home/chris/proethica/update_term_links_entity_types.py /home/chris/proethica/utils/migration/\n\n# Move run_debug_app.py to utils root as it's a general utility\nmv /home/chris/proethica/run_debug_app.py /home/chris/proethica/utils/)",
      "Bash(SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python scripts/check_ontologies.py)",
      "Bash(PYTHONPATH=/home/chris/proethica python scripts/sync_ontology_to_database.py --ontology engineering-ethics)",
      "Bash(PYTHONPATH=/home/chris/proethica python scripts/check_ontologies.py)",
      "Bash(pip install:*)",
      "Bash(git clone:*)",
      "Bash(docker build:*)",
      "Bash(docker-compose up:*)",
      "Bash(docker run:*)",
      "Bash(wget:*)",
      "Bash(java:*)",
      "Bash(sudo apt:*)",
      "Bash(sudo apt install:*)",
      "WebFetch(domain:github.com)",
      "Bash(tar:*)",
      "Bash(docker cp:*)",
      "Bash(docker restart:*)",
      "Bash(docker logs:*)",
      "Bash(docker stop:*)",
      "Bash(docker rm:*)",
      "Bash(systemctl status:*)",
      "Bash(service neo4j status:*)",
      "Bash(true)",
      "Bash(sudo netstat:*)",
      "Bash(ss:*)",
      "Bash(journalctl:*)",
      "Bash(export NEO4J_URI=bolt://localhost:7687)",
      "Bash(export NEO4J_USERNAME=neo4j)",
      "Bash(export NEO4J_PASSWORD=platypus)",
      "Bash(MCP_SERVER_PORT=5002 python mcp/enhanced_ontology_server_with_guidelines.py)",
      "Bash(./server_config/check-mcp-status.sh:*)",
      "Bash(./start_mcp_server_with_env.sh:*)",
      "Bash(./scripts/restart_mcp_server.sh:*)",
      "Bash(export MCP_SERVER_URL=\"http://localhost:5001\")",
      "Bash(echo:*)",
      "Bash(MCP_SERVER_PORT=5003 python -m mcp.enhanced_ontology_server_with_guidelines)",
      "Bash(scp:*)",
      "WebFetch(domain:www.nspe.org)",
      "WebFetch(domain:127.0.0.1)",
      "Bash(export SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\")",
      "Bash(git rev-parse:*)",
      "Bash(export FLASK_APP=app)",
      "Bash(flask shell:*)",
      "Bash(FLASK_APP=app flask shell)",
      "Bash(FLASK_APP=app python -c \"\nfrom app import create_app\nfrom app.models.document import Document\n\napp = create_app()\nwith app.app_context():\n    case8 = Document.query.get(8)\n    if case8:\n        print(''=== CASE 8 FOUND ==='')\n        print(f''ID: {case8.id}'')\n        print(f''Title: {case8.title}'')\n        print(f''Type: {case8.document_type}'')\n        print(f''World ID: {case8.world_id}'')\n        print(f''Source: {case8.source}'')\n        print(f''Processing Status: {case8.processing_status}'')\n        print()\n        print(''=== METADATA KEYS ==='')\n        if case8.doc_metadata:\n            for key, value in case8.doc_metadata.items():\n                if isinstance(value, str) and len(value) > 100:\n                    print(f''{key}: [LONG TEXT: {len(value)} chars]'')\n                elif isinstance(value, dict):\n                    print(f''{key}: [DICT with {len(value)} keys]'')\n                elif isinstance(value, list):\n                    print(f''{key}: [LIST with {len(value)} items]'')\n                else:\n                    print(f''{key}: {value}'')\n        else:\n            print(''No metadata found'')\n    else:\n        print(''Case 8 not found'')\n        docs = Document.query.all()\n        print(f''Found {len(docs)} documents total:'')\n        for doc in docs[:10]:\n            print(f''  {doc.id}: {doc.title} ({doc.document_type})'')\n\")",
      "Bash(FLASK_APP=app flask shell -c \"\nfrom app.models.scenario import Scenario\nfrom app.models.deconstructed_case import DeconstructedCase\nfrom app.services.scenario_population_service import ScenarioPopulationService\n\ntry:\n    # Check if scenario 1 exists\n    scenario = Scenario.query.get(1)\n    if scenario:\n        print(f''Found scenario: {scenario.name}'')\n        \n        # Check if there''s a deconstructed case for case 8\n        deconstructed_case = DeconstructedCase.query.filter_by(case_id=8).first()\n        if deconstructed_case:\n            print(f''Found deconstructed case for case 8: {deconstructed_case.id}'')\n            \n            # Show current state before population\n            from app.models.character import Character\n            from app.models.resource import Resource\n            from app.models.event import Event, Action\n            from app.models.condition import Condition\n            \n            before_chars = Character.query.filter_by(scenario_id=scenario.id).count()\n            before_resources = Resource.query.filter_by(scenario_id=scenario.id).count()\n            before_events = Event.query.filter_by(scenario_id=scenario.id).count()\n            before_actions = Action.query.filter_by(scenario_id=scenario.id).count()\n            \n            print(f''Before: {before_chars} characters, {before_resources} resources, {before_events} events, {before_actions} actions'')\n            \n            # Try to populate the scenario\n            result = ScenarioPopulationService.populate_scenario_from_deconstruction(scenario, deconstructed_case)\n            print(f''Population result: {result}'')\n            \n            if result:\n                # Check what was created\n                after_chars = Character.query.filter_by(scenario_id=scenario.id).count()\n                after_resources = Resource.query.filter_by(scenario_id=scenario.id).count()\n                after_events = Event.query.filter_by(scenario_id=scenario.id).count()\n                after_actions = Action.query.filter_by(scenario_id=scenario.id).count()\n                \n                print(f''After: {after_chars} characters, {after_resources} resources, {after_events} events, {after_actions} actions'')\n                \n                # Check scenario metadata\n                if scenario.scenario_metadata:\n                    print(f''Metadata keys: {list(scenario.scenario_metadata.keys())}'')\n                \n        else:\n            print(''No deconstructed case found for case 8'')\n    else:\n        print(''Scenario 1 not found'')\n        \nexcept Exception as e:\n    print(f''Error: {e}'')\n    import traceback\n    traceback.print_exc()\n\")",
      "Bash(FLASK_APP=app python3 -c \"\nfrom app import create_app\nfrom app.models.case import Case\nfrom app.models.deconstructed_case import DeconstructedCase\n\napp = create_app(''config'')\nwith app.app_context():\n    case = Case.query.get(8)\n    if case:\n        print(f''CASE 8: {case.title}'')\n        print(''='' * 80)\n        \n        # Look at questions section\n        if case.doc_metadata and ''sections_dual'' in case.doc_metadata:\n            sections = case.doc_metadata[''sections_dual'']\n            if ''questions'' in sections:\n                questions = sections[''questions'']\n                if ''text'' in questions:\n                    print(''QUESTIONS:'')\n                    print(questions[''text''][:500] + ''...'' if len(questions[''text'']) > 500 else questions[''text''])\n                    print()\n        \n        # Check deconstructed case\n        deconstructed = DeconstructedCase.query.filter_by(case_id=8).first()\n        if deconstructed:\n            print(''DECONSTRUCTED CASE STRUCTURE:'')\n            print(f''Stakeholders: {len(deconstructed.stakeholders)}'')\n            if deconstructed.stakeholders:\n                for i, stakeholder in enumerate(deconstructed.stakeholders[:3]):\n                    print(f''  {i+1}. {stakeholder.get(\"\"name\"\", \"\"Unknown\"\")} ({stakeholder.get(\"\"role\"\", \"\"Unknown\"\")})'')\n            \n            print(f''Decision Points: {len(deconstructed.decision_points)}'')\n            if deconstructed.decision_points:\n                for i, dp in enumerate(deconstructed.decision_points):\n                    print(f''  {i+1}. {dp.get(\"\"title\"\", \"\"Unknown\"\")}: {dp.get(\"\"description\"\", \"\"No description\"\")[:100]}...'')\n        \n    else:\n        print(''Case 8 not found'')\n\")",
      "Bash(FLASK_APP=app python3 -c \"\nfrom app import create_app\nfrom app.models import db, Case\nfrom app.models.deconstructed_case import DeconstructedCase\n\napp = create_app(''config'')\nwith app.app_context():\n    case = Case.query.get(8)\n    if case:\n        print(f''CASE 8: {case.title}'')\n        print(''='' * 80)\n        \n        # Look at questions section\n        if case.doc_metadata and ''sections_dual'' in case.doc_metadata:\n            sections = case.doc_metadata[''sections_dual'']\n            if ''questions'' in sections:\n                questions = sections[''questions'']\n                if ''text'' in questions:\n                    print(''QUESTIONS:'')\n                    print(questions[''text''])\n                    print()\n        \n        # Check deconstructed case\n        deconstructed = DeconstructedCase.query.filter_by(case_id=8).first()\n        if deconstructed:\n            print(''DECONSTRUCTED CASE STRUCTURE:'')\n            print(f''Stakeholders: {len(deconstructed.stakeholders)}'')\n            if deconstructed.stakeholders:\n                for i, stakeholder in enumerate(deconstructed.stakeholders[:3]):\n                    print(f''  {i+1}. {stakeholder.get(\"\"name\"\", \"\"Unknown\"\")} ({stakeholder.get(\"\"role\"\", \"\"Unknown\"\")})'')\n            \n            print(f''Decision Points: {len(deconstructed.decision_points)}'')\n            if deconstructed.decision_points:\n                for i, dp in enumerate(deconstructed.decision_points):\n                    print(f''  {i+1}. {dp.get(\"\"title\"\", \"\"Unknown\"\")}: {dp.get(\"\"description\"\", \"\"No description\"\")[:100]}...'')\n        \n    else:\n        print(''Case 8 not found'')\n\")",
      "Bash(FLASK_APP=app python3 -c \"\nfrom app import create_app\nfrom app.models import db, Document\nfrom app.models.deconstructed_case import DeconstructedCase\n\napp = create_app(''config'')\nwith app.app_context():\n    case = Document.query.get(8)\n    if case:\n        print(f''CASE 8: {case.title}'')\n        print(''='' * 80)\n        \n        # Look at questions section\n        if case.doc_metadata and ''sections_dual'' in case.doc_metadata:\n            sections = case.doc_metadata[''sections_dual'']\n            if ''questions'' in sections:\n                questions = sections[''questions'']\n                if ''text'' in questions:\n                    print(''QUESTIONS:'')\n                    print(questions[''text''])\n                    print(''\\n'' + ''='' * 80 + ''\\n'')\n        \n        # Check deconstructed case\n        deconstructed = DeconstructedCase.query.filter_by(case_id=8).first()\n        if deconstructed:\n            print(''DECONSTRUCTED CASE STRUCTURE:'')\n            print(f''Stakeholders: {len(deconstructed.stakeholders)}'')\n            if deconstructed.stakeholders:\n                for i, stakeholder in enumerate(deconstructed.stakeholders[:3]):\n                    print(f''  {i+1}. {stakeholder.get(\"\"name\"\", \"\"Unknown\"\")} ({stakeholder.get(\"\"role\"\", \"\"Unknown\"\")})'')\n            \n            print(f''\\nDecision Points: {len(deconstructed.decision_points)}'')\n            if deconstructed.decision_points:\n                for i, dp in enumerate(deconstructed.decision_points):\n                    print(f''  {i+1}. {dp.get(\"\"title\"\", \"\"Unknown\"\")}'')\n                    print(f''      Description: {dp.get(\"\"description\"\", \"\"No description\"\")[:150]}...'')\n                    if ''primary_options'' in dp:\n                        print(f''      Options: {len(dp[\"\"primary_options\"\"])}'')\n        \n    else:\n        print(''Case 8 not found'')\n\")",
      "Bash(FLASK_APP=app python3 -c \"\nfrom app import create_app\nfrom app.models import db, Document\n\napp = create_app(''config'')\nwith app.app_context():\n    case = Document.query.get(8)\n    if case and case.doc_metadata:\n        # Check all sections\n        sections = case.doc_metadata.get(''sections'', {})\n        for section_name, content in sections.items():\n            print(f''SECTION: {section_name.upper()}'')\n            if isinstance(content, dict):\n                text = content.get(''text'', content.get(''content'', ''''))\n            else:\n                text = content\n            print(text[:300] + ''...'' if len(str(text)) > 300 else text)\n            print(''\\n'' + ''='' * 80 + ''\\n'')\n\")",
      "Bash(FLASK_APP=app python3 -c \"\nfrom app import create_app\nfrom app.models import db\nfrom app.models.deconstructed_case import DeconstructedCase\n\napp = create_app(''config'')\nwith app.app_context():\n    # Delete existing deconstructed case for case 8\n    existing = DeconstructedCase.query.filter_by(case_id=8).first()\n    if existing:\n        print(f''Deleting existing deconstructed case {existing.id}'')\n        db.session.delete(existing)\n        db.session.commit()\n        print(''‚úÖ Deleted successfully'')\n    else:\n        print(''No existing deconstructed case found'')\n\")",
      "Bash(FLASK_APP=app python3:*)",
      "Bash(BYPASS_AUTH=true python3 -c \"\nfrom app import create_app\nimport os\n\napp = create_app(''config'')\nprint(f''BYPASS_AUTH: {os.environ.get(\"\"BYPASS_AUTH\"\")}'')\n\nwith app.test_client() as client:\n    with app.app_context():\n        print(''‚úÖ Testing wizard route with auth bypass'')\n        \n        response = client.get(''/scenarios/7/wizard'')\n        print(f''Status Code: {response.status_code}'')\n        print(f''Content-Type: {response.headers.get(\"\"Content-Type\"\")}'')\n        \n        if response.status_code == 200 and ''text/html'' in response.headers.get(''Content-Type'', ''''):\n            print(''‚úÖ Wizard route working correctly'')\n            content = response.data.decode(''utf-8'')\n            if ''Enhanced AI Ethics'' in content:\n                print(''‚úÖ Template rendered with scenario data'')\n            else:\n                print(''‚ùå Scenario data missing from template'')\n                print(f''Content preview: {content[:500]}...'')\n        else:\n            print(''‚ùå Response not as expected'')\n            print(f''Response: {response.data.decode(\"\"utf-8\"\")[:500]}'')\n\")",
      "Bash(BYPASS_AUTH=true python3:*)",
      "Bash(SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app, db\nfrom app.models.guideline import Guideline\nfrom app.models.ontology import Ontology\nfrom app.models.entity_triple import EntityTriple\n\napp = create_app()\nwith app.app_context():\n    # Check existing guidelines\n    guidelines = Guideline.query.all()\n    print(''=== EXISTING GUIDELINES ==='')\n    for g in guidelines:\n        print(f''ID: {g.id}, Title: {g.title}, World ID: {g.world_id}'')\n        triple_count = g.entity_triples.count()\n        print(f''  - Has {triple_count} entity triples'')\n    \n    print(f''\\nTotal guidelines: {len(guidelines)}'')\n    \n    # Check for derived ontologies\n    print(''\\n=== DERIVED ONTOLOGIES ==='')\n    derived_onts = Ontology.query.filter(Ontology.domain_id.like(''%guideline-%'')).all()\n    for ont in derived_onts:\n        print(f''ID: {ont.id}, Domain: {ont.domain_id}, Name: {ont.name}'')\n    \n    print(f''\\nTotal derived ontologies: {len(derived_onts)}'')\n\")",
      "Bash(ANTHROPIC_API_KEY=test python test_sync_status.py)",
      "Bash(unset:*)",
      "Bash(SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python3 -c \"\nfrom app import create_app, db\nfrom app.models.guideline import Guideline\nfrom app.models.ontology import Ontology\n\napp = create_app()\nwith app.app_context():\n    print(''=== GUIDELINES IN DATABASE ==='')\n    guidelines = Guideline.query.all()\n    print(f''Total guidelines: {len(guidelines)}'')\n    for g in guidelines:\n        print(f''  ID: {g.id}, Title: {g.title[:50]}..., World ID: {g.world_id}'')\n    \n    print(''\\n=== DERIVED ONTOLOGIES ==='')\n    derived_onts = Ontology.query.filter(Ontology.domain_id.like(''%guideline-%'')).all()\n    print(f''Total derived ontologies: {len(derived_onts)}'')\n    for ont in derived_onts:\n        print(f''  ID: {ont.id}, Domain: {ont.domain_id}, Name: {ont.name}'')\n        \n        # Check if the guideline still exists\n        if ''guideline-'' in ont.domain_id:\n            try:\n                guideline_id = int(ont.domain_id.split(''guideline-'')[1].split(''-'')[0])\n                guideline_exists = Guideline.query.get(guideline_id) is not None\n                print(f''    -> Guideline {guideline_id} exists: {guideline_exists}'')\n            except:\n                print(f''    -> Could not parse guideline ID from domain: {ont.domain_id}'')\n\")",
      "Bash(SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n\nfrom app import create_app, db\nfrom app.models.guideline import Guideline\nfrom app.models.ontology import Ontology\n\napp = create_app()\nwith app.app_context():\n    print(''=== GUIDELINES IN DATABASE ==='')\n    guidelines = Guideline.query.all()\n    print(f''Total guidelines: {len(guidelines)}'')\n    for g in guidelines:\n        print(f''  ID: {g.id}, Title: {g.title[:50]}..., World ID: {g.world_id}'')\n    \n    print(''\\n=== DERIVED ONTOLOGIES ==='')\n    derived_onts = Ontology.query.filter(Ontology.domain_id.like(''%guideline-%'')).all()\n    print(f''Total derived ontologies: {len(derived_onts)}'')\n    for ont in derived_onts:\n        print(f''  ID: {ont.id}, Domain: {ont.domain_id}, Name: {ont.name}'')\n        \n        # Check if the guideline still exists\n        if ''guideline-'' in ont.domain_id:\n            try:\n                guideline_id = int(ont.domain_id.split(''guideline-'')[1].split(''-'')[0])\n                guideline_exists = Guideline.query.get(guideline_id) is not None\n                print(f''    -> Guideline {guideline_id} exists: {guideline_exists}'')\n            except:\n                print(f''    -> Could not parse guideline ID from domain: {ont.domain_id}'')\n\")",
      "Bash(SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python3 -c \"\nfrom app import create_app\nfrom app.models.world import World\nfrom app.services.ontology_entity_service import OntologyEntityService\n\napp = create_app()\nwith app.app_context():\n    world = World.query.get(1)\n    if world:\n        print(f''World 1: {world.name}'')\n        print(f''Ontology ID: {world.ontology_id}'')\n        \n        service = OntologyEntityService.get_instance()\n        service.invalidate_cache()  # Clear any cache\n        entities = service.get_entities_for_world(world)\n        \n        print(f''\\nEntity categories found:'')\n        if ''entities'' in entities:\n            for entity_type, entity_list in entities[''entities''].items():\n                print(f''  {entity_type}: {len(entity_list)} entities'')\n                if len(entity_list) > 0:\n                    print(f''    Sample entities: {[e[\"\"label\"\"] for e in entity_list[:5]]}'')\n        else:\n            print(''No entities found'')\n    else:\n        print(''World 1 not found'')\n\")",
      "Bash(SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n\nfrom app import create_app\nfrom app.models.world import World\nfrom app.services.ontology_entity_service import OntologyEntityService\n\napp = create_app()\nwith app.app_context():\n    world = World.query.get(1)\n    if world:\n        print(f''World 1: {world.name}'')\n        print(f''Ontology ID: {world.ontology_id}'')\n        \n        service = OntologyEntityService.get_instance()\n        # Clear any cache\n        service.ontology_cache = {}\n        entities = service.get_entities_for_world(world)\n        \n        print(f''\\nEntity categories found:'')\n        if ''entities'' in entities:\n            for entity_type, entity_list in entities[''entities''].items():\n                print(f''  {entity_type}: {len(entity_list)} entities'')\n                if len(entity_list) > 0:\n                    print(f''    Sample entities: {[e[\"\"label\"\"] for e in entity_list[:5]]}'')\n        else:\n            print(''No entities found'')\n            \n        # Also check for specific overlapping entities you mentioned\n        print(f''\\nLooking for specific entities you mentioned:'')\n        if ''entities'' in entities:\n            for entity_type, entity_list in entities[''entities''].items():\n                for entity in entity_list:\n                    if ''public safety'' in entity.get(''label'', '''').lower():\n                        print(f''  Found \"\"public safety\"\" in {entity_type}: {entity[\"\"label\"\"]}'')\n                    if ''ethical dilemma'' in entity.get(''label'', '''').lower():\n                        print(f''  Found \"\"ethical dilemma\"\" in {entity_type}: {entity[\"\"label\"\"]}'')\n                    if ''coordination'' in entity.get(''label'', '''').lower():\n                        print(f''  Found \"\"coordination\"\" in {entity_type}: {entity[\"\"label\"\"]}'')\n    else:\n        print(''World 1 not found'')\n\")",
      "Bash(awk:*)",
      "Bash(SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python3 -c \"\nfrom app import create_app, db\nfrom app.models.ontology import Ontology\n\napp = create_app()\nwith app.app_context():\n    # Check for any guideline-derived ontologies\n    derived_onts = Ontology.query.filter(Ontology.domain_id.like(''guideline-%'')).all()\n    print(f''Found {len(derived_onts)} guideline-derived ontologies:'')\n    for ont in derived_onts:\n        print(f''  - ID: {ont.id}, Domain: {ont.domain_id}, Name: {ont.name}'')\n\")",
      "Bash(export DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm)",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\n\napp = create_app(''config'')\n\nwith app.app_context():\n    from app.models.ontology import Ontology\n    # Check for any guideline-derived ontologies\n    derived_onts = Ontology.query.filter(Ontology.domain_id.like(''guideline-%'')).all()\n    print(f''Found {len(derived_onts)} guideline-derived ontologies:'')\n    for ont in derived_onts:\n        print(f''  - ID: {ont.id}, Domain: {ont.domain_id}'')\n        print(f''    Name: {ont.name}'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\n\napp = create_app(''config'')\n\nwith app.app_context():\n    from app.models.ontology import Ontology\n    from app.models.guideline import Guideline\n    from app.models.document import Document\n    \n    # Check document 27\n    doc = Document.query.get(27)\n    if doc:\n        print(f''Document 27: {doc.title}'')\n        print(f''  Type: {doc.document_type}'')\n        if doc.doc_metadata and ''guideline_id'' in doc.doc_metadata:\n            print(f''  Actual guideline ID: {doc.doc_metadata[\"\"guideline_id\"\"]}'')\n    \n    # Check for derived ontology\n    derived_domain = ''guideline-27-concepts''\n    derived_ont = Ontology.query.filter_by(domain_id=derived_domain).first()\n    if derived_ont:\n        print(f''\\nDerived ontology exists:'')\n        print(f''  ID: {derived_ont.id}'')\n        print(f''  Domain: {derived_ont.domain_id}'')\n        print(f''  Name: {derived_ont.name}'')\n    else:\n        print(f''\\nNo derived ontology found with domain: {derived_domain}'')\n    \n    # Check all guideline-related ontologies\n    all_guideline_onts = Ontology.query.filter(Ontology.domain_id.like(''guideline-%'')).all()\n    print(f''\\nAll guideline ontologies: {len(all_guideline_onts)}'')\n    for ont in all_guideline_onts:\n        print(f''  - {ont.domain_id}: {ont.name}'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\n\napp = create_app(''config'')\n\nwith app.app_context():\n    from app.models.guideline import Guideline\n    \n    # Check if Guideline with ID 2 or 27 exists\n    g2 = Guideline.query.get(2)\n    g27 = Guideline.query.get(27)\n    \n    print(''Guideline 2:'', ''EXISTS'' if g2 else ''NOT FOUND'')\n    if g2:\n        print(f''  Title: {g2.title}'')\n    \n    print(''Guideline 27:'', ''EXISTS'' if g27 else ''NOT FOUND'')\n    if g27:\n        print(f''  Title: {g27.title}'')\n    \n    # Check all guidelines\n    all_guidelines = Guideline.query.all()\n    print(f''\\nTotal guidelines in database: {len(all_guidelines)}'')\n    for g in all_guidelines:\n        print(f''  ID {g.id}: {g.title[:50]}...'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\n\napp = create_app(''config'')\n\nwith app.app_context():\n    from app.models.ontology import Ontology\n    from app.services.guideline_concept_integration_service import GuidelineConceptIntegrationService\n    \n    # Check for derived ontology for document 27\n    derived_domain = ''guideline-27-concepts''\n    derived_ont = Ontology.query.filter_by(domain_id=derived_domain).first()\n    if derived_ont:\n        print(f''‚úÖ Derived ontology exists:'')\n        print(f''  ID: {derived_ont.id}'')\n        print(f''  Domain: {derived_ont.domain_id}'')\n        print(f''  Name: {derived_ont.name}'')\n        \n        # Test the check_concepts_added_to_ontology method\n        print(f''\\nüîç Testing ontology status check...'')\n        try:\n            status = GuidelineConceptIntegrationService.check_concepts_added_to_ontology(\n                guideline_id=27,  # Document ID\n                ontology_domain=''engineering-ethics''\n            )\n            print(f''Status result:'')\n            for key, value in status.items():\n                print(f''  {key}: {value}'')\n        except Exception as e:\n            print(f''‚ùå Error checking status: {e}'')\n            import traceback\n            traceback.print_exc()\n    else:\n        print(f''‚ùå No derived ontology found with domain: {derived_domain}'')\n        \n        # Check all guideline ontologies\n        all_guideline_onts = Ontology.query.filter(Ontology.domain_id.like(''guideline-%'')).all()\n        print(f''\\nAll guideline ontologies: {len(all_guideline_onts)}'')\n        for ont in all_guideline_onts:\n            print(f''  - {ont.domain_id}: {ont.name}'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\n\napp = create_app(''config'')\n\nwith app.app_context():\n    from app.models.document import Document\n    from app.models.guideline import Guideline\n    \n    print(''üìä DASHBOARD DATA - All guidelines in database:'')\n    all_guidelines = Guideline.query.all()\n    print(f''Total Guideline records: {len(all_guidelines)}'')\n    for g in all_guidelines:\n        print(f''  ID {g.id}: {g.title}'')\n    \n    print(''\\nüìÑ GUIDELINES PAGE DATA - Documents with type=guideline:'')\n    guideline_docs = Document.query.filter_by(document_type=''guideline'').all()\n    print(f''Total Document records with type=guideline: {len(guideline_docs)}'')\n    for doc in guideline_docs:\n        print(f''  ID {doc.id}: {doc.title} (World: {doc.world_id})'')\n    \n    print(''\\nüåç WORLD-SPECIFIC GUIDELINES:'')\n    world1_guidelines = Document.query.filter_by(world_id=1, document_type=''guideline'').all()\n    print(f''World 1 guideline documents: {len(world1_guidelines)}'')\n    for doc in world1_guidelines:\n        print(f''  ID {doc.id}: {doc.title}'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\n\napp = create_app(''config'')\n\nwith app.app_context():\n    from app.models.document import Document\n    from app.models.guideline import Guideline\n    \n    print(''üîç Checking world relationships...'')\n    \n    # Check if Guidelines have world_id\n    guidelines_with_world = Guideline.query.filter(Guideline.world_id.isnot(None)).all()\n    print(f''Guidelines with world_id: {len(guidelines_with_world)}'')\n    for g in guidelines_with_world:\n        print(f''  Guideline {g.id}: world_id={g.world_id}'')\n    \n    # Check if Documents have world_id\n    docs_with_world = Document.query.filter(Document.world_id.isnot(None)).all()\n    print(f''\\nDocuments with world_id: {len(docs_with_world)}'')\n    for d in docs_with_world:\n        print(f''  Document {d.id}: world_id={d.world_id}, type={d.document_type}'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\n\napp = create_app(''config'')\n\nwith app.app_context():\n    from app.models.document import Document\n    from app.models.guideline import Guideline\n    from app.models.entity_triple import EntityTriple\n    \n    print(''üîç INVESTIGATING ORPHANED GUIDELINE RECORDS'')\n    print(''='' * 60)\n    \n    # Get all Guidelines\n    all_guidelines = Guideline.query.all()\n    print(f''\\nüìä Guidelines table has {len(all_guidelines)} records:'')\n    for g in all_guidelines:\n        print(f''  Guideline ID {g.id}:'')\n        print(f''    Title: {g.title}'')\n        print(f''    World ID: {g.world_id}'')\n        print(f''    Created: {g.created_at}'')\n        \n        # Check for related Document\n        related_docs = Document.query.filter(\n            Document.doc_metadata.op(''->>'')(''guideline_id'').astext == str(g.id)\n        ).all()\n        \n        if related_docs:\n            print(f''    ‚úÖ Has {len(related_docs)} related Document(s):'')\n            for doc in related_docs:\n                print(f''       - Document {doc.id}: {doc.title} (type: {doc.document_type})'')\n        else:\n            print(f''    ‚ùå ORPHANED - No related Document found'')\n        \n        # Check for EntityTriples\n        triples = EntityTriple.query.filter_by(guideline_id=g.id).count()\n        print(f''    Entity Triples: {triples}'')\n        \n        # Check metadata\n        if g.guideline_metadata:\n            concepts = g.guideline_metadata.get(''concepts'', [])\n            print(f''    Concepts in metadata: {len(concepts)}'')\n    \n    print(''\\n'' + ''='' * 60)\n    print(''üìÑ Documents with type=guideline:'')\n    guideline_docs = Document.query.filter_by(document_type=''guideline'').all()\n    for doc in guideline_docs:\n        print(f''  Document ID {doc.id}:'')\n        print(f''    Title: {doc.title}'')\n        print(f''    World ID: {doc.world_id}'')\n        if doc.doc_metadata and ''guideline_id'' in doc.doc_metadata:\n            print(f''    Points to Guideline ID: {doc.doc_metadata[\"\"guideline_id\"\"]}'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\n\napp = create_app(''config'')\n\nwith app.app_context():\n    from app.models.guideline import Guideline\n    from app import db\n    \n    # Find and delete orphaned Guideline ID 1\n    orphaned_guideline = Guideline.query.get(1)\n    \n    if orphaned_guideline:\n        print(f''üóëÔ∏è Found orphaned Guideline ID 1: {orphaned_guideline.title}'')\n        print(f''  Created: {orphaned_guideline.created_at}'')\n        print(f''  World ID: {orphaned_guideline.world_id}'')\n        \n        # Delete it\n        db.session.delete(orphaned_guideline)\n        db.session.commit()\n        print(''‚úÖ Successfully deleted orphaned Guideline ID 1'')\n    else:\n        print(''‚ùå Guideline ID 1 not found (may have already been deleted)'')\n    \n    # Verify deletion\n    remaining_guidelines = Guideline.query.all()\n    print(f''\\nüìä Remaining Guidelines in database: {len(remaining_guidelines)}'')\n    for g in remaining_guidelines:\n        print(f''  ID {g.id}: {g.title} (World {g.world_id})'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\n\napp = create_app(''config'')\n\nwith app.app_context():\n    from app.models.ontology import Ontology\n    from app.models.document import Document\n    from app import db\n    \n    # Find the existing derived ontology\n    derived_ont = Ontology.query.filter_by(domain_id=''guideline-27-concepts'').first()\n    if derived_ont:\n        print(f''Found derived ontology:'')\n        print(f''  Current name: {derived_ont.name}'')\n        \n        # Get the document to find the actual guideline title\n        doc = Document.query.get(27)\n        if doc:\n            new_name = f''{doc.title} - Concepts''\n            print(f''  New name: {new_name}'')\n            \n            # Update the name\n            derived_ont.name = new_name\n            db.session.commit()\n            \n            print(''‚úÖ Successfully updated derived ontology name'')\n        else:\n            print(''‚ùå Document 27 not found'')\n    else:\n        print(''‚ùå Derived ontology not found'')\n    \n    # Verify the update\n    updated_ont = Ontology.query.filter_by(domain_id=''guideline-27-concepts'').first()\n    if updated_ont:\n        print(f''\\nüìã Updated ontology details:'')\n        print(f''  ID: {updated_ont.id}'')\n        print(f''  Name: {updated_ont.name}'')\n        print(f''  Description: {updated_ont.description}'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\n\napp = create_app(''config'')\n\nwith app.app_context():\n    from app.models.document import Document\n    \n    # Check case 7 first\n    case7 = Document.query.get(7)\n    if case7:\n        print(''üîç CASE 7 EXAMINATION'')\n        print(f''Title: {case7.title}'')\n        print(f''Type: {case7.document_type}'')\n        print()\n        \n        if case7.doc_metadata:\n            print(''üìã Metadata keys:'')\n            for key in sorted(case7.doc_metadata.keys()):\n                value = case7.doc_metadata[key]\n                if isinstance(value, str) and len(value) > 100:\n                    print(f''  {key}: [TEXT: {len(value)} chars]'')\n                elif isinstance(value, (list, dict)):\n                    print(f''  {key}: {type(value).__name__} with {len(value)} items'')\n                else:\n                    print(f''  {key}: {value}'')\n            \n            # Check for subject references specifically\n            if ''subject_references'' in case7.doc_metadata:\n                refs = case7.doc_metadata[''subject_references'']\n                print(f''\\nüìå Subject References: {refs}'')\n            \n            # Check sections for references\n            if ''sections'' in case7.doc_metadata:\n                sections = case7.doc_metadata[''sections'']\n                if ''references'' in sections:\n                    print(f''\\nüîó References section: {sections[\"\"references\"\"]}'')\n        else:\n            print(''‚ùå No metadata found'')\n    else:\n        print(''‚ùå Case 7 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\n\napp = create_app(''config'')\n\nwith app.app_context():\n    from app.models.document import Document\n    \n    case7 = Document.query.get(7)\n    if case7 and case7.doc_metadata:\n        print(''üìå CASE 7 SUBJECT TAGS:'')\n        tags = case7.doc_metadata.get(''subject_tags'', [])\n        for i, tag in enumerate(tags, 1):\n            print(f''  {i}. {tag}'')\n        \n        print(f''\\nTotal: {len(tags)} subject tags'')\n    else:\n        print(''‚ùå Case 7 not found or no metadata'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\n\napp = create_app(''config'')\n\nwith app.app_context():\n    from app.models.document import Document\n    \n    print(''üîç CHECKING ALL CASES FOR SUBJECT TAGS'')\n    print(''='' * 60)\n    \n    cases = Document.query.filter_by(document_type=''case_study'').all()\n    \n    cases_with_tags = []\n    cases_without_tags = []\n    \n    for case in cases:\n        has_tags = (case.doc_metadata and \n                   ''subject_tags'' in case.doc_metadata and \n                   case.doc_metadata[''subject_tags''])\n        \n        case_info = {\n            ''id'': case.id,\n            ''title'': case.title,\n            ''case_number'': case.doc_metadata.get(''case_number'', ''N/A'') if case.doc_metadata else ''N/A'',\n            ''year'': case.doc_metadata.get(''year'', ''N/A'') if case.doc_metadata else ''N/A'',\n            ''tag_count'': len(case.doc_metadata.get(''subject_tags'', [])) if case.doc_metadata else 0\n        }\n        \n        if has_tags:\n            cases_with_tags.append(case_info)\n        else:\n            cases_without_tags.append(case_info)\n    \n    print(f''‚úÖ CASES WITH SUBJECT TAGS ({len(cases_with_tags)}):'')\n    for case in sorted(cases_with_tags, key=lambda x: x[''id'']):\n        print(f''  Case {case[\"\"id\"\"]} ({case[\"\"case_number\"\"]}): {case[\"\"title\"\"][:50]}... - {case[\"\"tag_count\"\"]} tags'')\n    \n    print(f''\\n‚ùå CASES WITHOUT SUBJECT TAGS ({len(cases_without_tags)}):'')\n    for case in sorted(cases_without_tags, key=lambda x: x[''id'']):\n        print(f''  Case {case[\"\"id\"\"]} ({case[\"\"case_number\"\"]}): {case[\"\"title\"\"][:50]}...'')\n    \n    print(f''\\nüìä SUMMARY:'')\n    print(f''  Total cases: {len(cases)}'')\n    print(f''  With tags: {len(cases_with_tags)} ({len(cases_with_tags)/len(cases)*100:.1f}%)'')\n    print(f''  Without tags: {len(cases_without_tags)} ({len(cases_without_tags)/len(cases)*100:.1f}%)'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\n\napp = create_app(''config'')\n\nwith app.app_context():\n    from app.models.document import Document\n    \n    # Check a few cases to see if they have source URLs for re-extraction\n    print(''üîç CHECKING CASES FOR SOURCE URLs'')\n    print(''='' * 50)\n    \n    cases_without_tags = Document.query.filter_by(document_type=''case_study'').all()\n    \n    for case in cases_without_tags[:5]:  # Check first 5\n        has_tags = (case.doc_metadata and \n                   ''subject_tags'' in case.doc_metadata and \n                   case.doc_metadata[''subject_tags''])\n        \n        if not has_tags:\n            print(f''\\nCase {case.id} ({case.doc_metadata.get(\"\"case_number\"\", \"\"N/A\"\") if case.doc_metadata else \"\"N/A\"\"}):'')\n            print(f''  Title: {case.title[:60]}...'')\n            \n            if case.source_url:\n                print(f''  Source URL: {case.source_url}'')\n            elif case.source:\n                print(f''  Source: {case.source}'')\n            else:\n                print(''  ‚ùå No source URL available'')\n                \n            # Check if references section exists with subject reference links\n            if (case.doc_metadata and ''sections'' in case.doc_metadata and \n                ''references'' in case.doc_metadata[''sections'']):\n                refs = case.doc_metadata[''sections''][''references'']\n                if ''subject-reference-guide-code-ethics'' in str(refs):\n                    print(''  ‚úÖ References section contains subject reference links'')\n                else:\n                    print(''  ‚ùå No subject reference links in references section'')\n            else:\n                print(''  ‚ùå No references section available'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\n\napp = create_app(''config'')\n\nwith app.app_context():\n    from app.models.document import Document\n    \n    # Check a few cases to see if they have source URLs for re-extraction\n    print(''üîç CHECKING CASES FOR SOURCE URLs AND REFERENCES'')\n    print(''='' * 60)\n    \n    cases_without_tags = [c for c in Document.query.filter_by(document_type=''case_study'').all() \n                         if not (c.doc_metadata and ''subject_tags'' in c.doc_metadata and c.doc_metadata[''subject_tags''])]\n    \n    for i, case in enumerate(cases_without_tags[:3]):  # Check first 3\n        print(f''\\nCase {case.id} ({case.doc_metadata.get(\"\"case_number\"\", \"\"N/A\"\") if case.doc_metadata else \"\"N/A\"\"}):'')\n        print(f''  Title: {case.title[:60]}...'')\n        \n        # Check source attribute\n        if hasattr(case, ''source'') and case.source:\n            print(f''  Source: {case.source}'')\n        else:\n            print(''  ‚ùå No source URL available'')\n            \n        # Check if references section exists with subject reference links\n        if (case.doc_metadata and ''sections'' in case.doc_metadata and \n            ''references'' in case.doc_metadata[''sections'']):\n            refs = case.doc_metadata[''sections''][''references'']\n            if ''subject-reference-guide-code-ethics'' in str(refs):\n                print(''  ‚úÖ References section contains subject reference links'')\n                # Try to count the links\n                import re\n                links = re.findall(r''subject-reference-guide-code-ethics/[^\"\"]*'', str(refs))\n                print(f''     Found {len(set(links))} unique subject reference links'')\n            else:\n                print(''  ‚ùå No subject reference links in references section'')\n        else:\n            print(''  ‚ùå No references section available'')\n    \n    print(f''\\nüìä Total cases without subject tags: {len(cases_without_tags)}'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\n\napp = create_app(''config'')\n\nwith app.app_context():\n    from app.models.document import Document\n    \n    print(''‚úÖ VERIFICATION - POST-MIGRATION STATUS'')\n    print(''='' * 50)\n    \n    cases = Document.query.filter_by(document_type=''case_study'').all()\n    \n    cases_with_tags = []\n    cases_without_tags = []\n    \n    for case in cases:\n        has_tags = (case.doc_metadata and \n                   ''subject_tags'' in case.doc_metadata and \n                   case.doc_metadata[''subject_tags''])\n        \n        case_info = {\n            ''id'': case.id,\n            ''title'': case.title,\n            ''case_number'': case.doc_metadata.get(''case_number'', ''N/A'') if case.doc_metadata else ''N/A'',\n            ''tag_count'': len(case.doc_metadata.get(''subject_tags'', [])) if case.doc_metadata else 0\n        }\n        \n        if has_tags:\n            cases_with_tags.append(case_info)\n        else:\n            cases_without_tags.append(case_info)\n    \n    print(f''‚úÖ CASES WITH SUBJECT TAGS ({len(cases_with_tags)}):'')\n    for case in sorted(cases_with_tags, key=lambda x: x[''id''])[:10]:  # Show first 10\n        print(f''  Case {case[\"\"id\"\"]} ({case[\"\"case_number\"\"]}): {case[\"\"title\"\"][:45]}... - {case[\"\"tag_count\"\"]} tags'')\n    \n    if len(cases_with_tags) > 10:\n        print(f''  ... and {len(cases_with_tags) - 10} more cases'')\n    \n    if cases_without_tags:\n        print(f''\\n‚ùå REMAINING CASES WITHOUT TAGS ({len(cases_without_tags)}):'')\n        for case in sorted(cases_without_tags, key=lambda x: x[''id'']):\n            print(f''  Case {case[\"\"id\"\"]} ({case[\"\"case_number\"\"]}): {case[\"\"title\"\"][:50]}...'')\n    else:\n        print(f''\\nüéâ NO REMAINING CASES WITHOUT TAGS!'')\n    \n    print(f''\\nüìä FINAL SUMMARY:'')\n    print(f''  Total cases: {len(cases)}'')\n    print(f''  With tags: {len(cases_with_tags)} ({len(cases_with_tags)/len(cases)*100:.1f}%)'')\n    print(f''  Without tags: {len(cases_without_tags)} ({len(cases_without_tags)/len(cases)*100:.1f}%)'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nimport sys\nfrom bs4 import BeautifulSoup\n\n# Add the project root to the Python path\nsys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))\n\n# Set up environment\nos.environ[''SQLALCHEMY_DATABASE_URI''] = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n\nfrom app import create_app, db\nfrom app.models.document import Document\nfrom app.services.case_processing.pipeline_steps.nspe_extraction_step import NSPECaseExtractionStep\nfrom sqlalchemy.orm.attributes import flag_modified\n\ndef extract_subject_tags_from_references(references_html):\n    if not references_html:\n        return []\n    \n    # Create a BeautifulSoup object from the references HTML\n    soup = BeautifulSoup(references_html, ''html.parser'')\n    \n    # Use the existing NSPECaseExtractionStep logic\n    extraction_step = NSPECaseExtractionStep()\n    subject_tags = extraction_step.extract_subject_tags(soup)\n    \n    return subject_tags\n\napp = create_app(''config'')\n\nwith app.app_context():\n    print(''üîÑ MIGRATING SUBJECT TAGS FROM EXISTING REFERENCES'')\n    print(''='' * 60)\n    \n    # Find all cases without subject_tags\n    cases_without_tags = []\n    all_cases = Document.query.filter_by(document_type=''case_study'').all()\n    \n    for case in all_cases:\n        has_tags = (case.doc_metadata and \n                   ''subject_tags'' in case.doc_metadata and \n                   case.doc_metadata[''subject_tags''])\n        if not has_tags:\n            cases_without_tags.append(case)\n    \n    print(f''üìä Found {len(cases_without_tags)} cases without subject tags'')\n    print()\n    \n    successful_extractions = 0\n    failed_extractions = 0\n    \n    for i, case in enumerate(cases_without_tags, 1):\n        case_number = case.doc_metadata.get(''case_number'', ''N/A'') if case.doc_metadata else ''N/A''\n        print(f''[{i}/{len(cases_without_tags)}] Case {case.id} ({case_number}): {case.title[:50]}...'')\n        \n        # Check if references section exists\n        if not (case.doc_metadata and ''sections'' in case.doc_metadata and \n                ''references'' in case.doc_metadata[''sections'']):\n            print(''  ‚ùå No references section found'')\n            failed_extractions += 1\n            continue\n        \n        references_html = case.doc_metadata[''sections''][''references'']\n        \n        # Extract subject tags from references\n        try:\n            subject_tags = extract_subject_tags_from_references(references_html)\n            \n            if subject_tags:\n                print(f''  ‚úÖ Extracted {len(subject_tags)} tags: {'', ''.join(subject_tags[:3])}{''...'' if len(subject_tags) > 3 else ''''}'')\n                \n                # Update the case metadata\n                if not case.doc_metadata:\n                    case.doc_metadata = {}\n                case.doc_metadata[''subject_tags''] = subject_tags\n                \n                # Mark the document as modified (for SQLAlchemy to detect changes in JSONB)\n                flag_modified(case, ''doc_metadata'')\n                \n                successful_extractions += 1\n            else:\n                print(''  ‚ùå No subject tags found in references'')\n                failed_extractions += 1\n                \n        except Exception as e:\n            print(f''  ‚ùå Error extracting tags: {str(e)}'')\n            failed_extractions += 1\n    \n    print()\n    print(''üìä MIGRATION SUMMARY:'')\n    print(f''  Total cases processed: {len(cases_without_tags)}'')\n    print(f''  Successful extractions: {successful_extractions}'')\n    print(f''  Failed extractions: {failed_extractions}'')\n    print(f''  Success rate: {(successful_extractions/len(cases_without_tags)*100):.1f}%'' if cases_without_tags else ''N/A'')\n    \n    if successful_extractions > 0:\n        print()\n        print(''üíæ Committing changes to database...'')\n        try:\n            db.session.commit()\n            print(''‚úÖ Successfully updated database'')\n        except Exception as e:\n            print(f''‚ùå Error committing changes: {str(e)}'')\n            db.session.rollback()\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nimport sys\nfrom bs4 import BeautifulSoup\n\n# Add the project root to the Python path\nsys.path.insert(0, ''/home/chris/onto/proethica'')\n\n# Set up environment\nos.environ[''SQLALCHEMY_DATABASE_URI''] = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n\nfrom app import create_app, db\nfrom app.models.document import Document\nfrom app.services.case_processing.pipeline_steps.nspe_extraction_step import NSPECaseExtractionStep\nfrom sqlalchemy.orm.attributes import flag_modified\n\ndef extract_subject_tags_from_references(references_html):\n    if not references_html:\n        return []\n    \n    # Create a BeautifulSoup object from the references HTML\n    soup = BeautifulSoup(references_html, ''html.parser'')\n    \n    # Use the existing NSPECaseExtractionStep logic\n    extraction_step = NSPECaseExtractionStep()\n    subject_tags = extraction_step.extract_subject_tags(soup)\n    \n    return subject_tags\n\napp = create_app(''config'')\n\nwith app.app_context():\n    print(''üîÑ MIGRATING SUBJECT TAGS FROM EXISTING REFERENCES'')\n    print(''='' * 60)\n    \n    # Find all cases without subject_tags\n    cases_without_tags = []\n    all_cases = Document.query.filter_by(document_type=''case_study'').all()\n    \n    for case in all_cases:\n        has_tags = (case.doc_metadata and \n                   ''subject_tags'' in case.doc_metadata and \n                   case.doc_metadata[''subject_tags''])\n        if not has_tags:\n            cases_without_tags.append(case)\n    \n    print(f''üìä Found {len(cases_without_tags)} cases without subject tags'')\n    print()\n    \n    successful_extractions = 0\n    failed_extractions = 0\n    \n    for i, case in enumerate(cases_without_tags, 1):\n        case_number = case.doc_metadata.get(''case_number'', ''N/A'') if case.doc_metadata else ''N/A''\n        print(f''[{i}/{len(cases_without_tags)}] Case {case.id} ({case_number}): {case.title[:50]}...'')\n        \n        # Check if references section exists\n        if not (case.doc_metadata and ''sections'' in case.doc_metadata and \n                ''references'' in case.doc_metadata[''sections'']):\n            print(''  ‚ùå No references section found'')\n            failed_extractions += 1\n            continue\n        \n        references_html = case.doc_metadata[''sections''][''references'']\n        \n        # Extract subject tags from references\n        try:\n            subject_tags = extract_subject_tags_from_references(references_html)\n            \n            if subject_tags:\n                print(f''  ‚úÖ Extracted {len(subject_tags)} tags: {'', ''.join(subject_tags[:3])}{''...'' if len(subject_tags) > 3 else ''''}'')\n                \n                # Update the case metadata\n                if not case.doc_metadata:\n                    case.doc_metadata = {}\n                case.doc_metadata[''subject_tags''] = subject_tags\n                \n                # Mark the document as modified (for SQLAlchemy to detect changes in JSONB)\n                flag_modified(case, ''doc_metadata'')\n                \n                successful_extractions += 1\n            else:\n                print(''  ‚ùå No subject tags found in references'')\n                failed_extractions += 1\n                \n        except Exception as e:\n            print(f''  ‚ùå Error extracting tags: {str(e)}'')\n            failed_extractions += 1\n    \n    print()\n    print(''üìä MIGRATION SUMMARY:'')\n    print(f''  Total cases processed: {len(cases_without_tags)}'')\n    print(f''  Successful extractions: {successful_extractions}'')\n    print(f''  Failed extractions: {failed_extractions}'')\n    print(f''  Success rate: {(successful_extractions/len(cases_without_tags)*100):.1f}%'' if cases_without_tags else ''N/A'')\n    \n    if successful_extractions > 0:\n        print()\n        print(''üíæ Committing changes to database...'')\n        try:\n            db.session.commit()\n            print(''‚úÖ Successfully updated database'')\n        except Exception as e:\n            print(f''‚ùå Error committing changes: {str(e)}'')\n            db.session.rollback()\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\n\napp = create_app(''config'')\n\nwith app.app_context():\n    from app.models.document import Document\n    \n    print(''üîç VERIFICATION - CASES WITH SUBJECT TAGS AFTER MIGRATION'')\n    print(''='' * 70)\n    \n    cases_with_tags = []\n    cases_without_tags = []\n    all_cases = Document.query.filter_by(document_type=''case_study'').all()\n    \n    for case in all_cases:\n        has_tags = (case.doc_metadata and \n                   ''subject_tags'' in case.doc_metadata and \n                   case.doc_metadata[''subject_tags''])\n        \n        case_info = {\n            ''id'': case.id,\n            ''title'': case.title,\n            ''case_number'': case.doc_metadata.get(''case_number'', ''N/A'') if case.doc_metadata else ''N/A'',\n            ''tag_count'': len(case.doc_metadata.get(''subject_tags'', [])) if case.doc_metadata else 0\n        }\n        \n        if has_tags:\n            cases_with_tags.append(case_info)\n        else:\n            cases_without_tags.append(case_info)\n    \n    print(f''‚úÖ CASES WITH SUBJECT TAGS ({len(cases_with_tags)}):'')\n    for case in sorted(cases_with_tags, key=lambda x: x[''id'']):\n        print(f''  Case {case[''id'']} ({case[''case_number'']}): {case[''title''][:50]}... - {case[''tag_count'']} tags'')\n    \n    print(f''\\n‚ùå CASES WITHOUT SUBJECT TAGS ({len(cases_without_tags)}):'')\n    for case in sorted(cases_without_tags, key=lambda x: x[''id'']):\n        print(f''  Case {case[''id'']} ({case[''case_number'']}): {case[''title''][:50]}...'')\n    \n    print(f''\\nüìä FINAL SUMMARY:'')\n    print(f''  Total cases: {len(all_cases)}'')\n    print(f''  With tags: {len(cases_with_tags)} ({len(cases_with_tags)/len(all_cases)*100:.1f}%)'')\n    print(f''  Without tags: {len(cases_without_tags)} ({len(cases_without_tags)/len(all_cases)*100:.1f}%)'')\n    \n    # Show sample tags from a few cases\n    print(f''\\nüè∑Ô∏è SAMPLE SUBJECT TAGS:'')\n    sample_cases = sorted(cases_with_tags, key=lambda x: x[''tag_count''], reverse=True)[:3]\n    for case_info in sample_cases:\n        case = Document.query.get(case_info[''id''])\n        tags = case.doc_metadata.get(''subject_tags'', [])\n        print(f''\\nCase {case.id} ({case_info[''case_number'']}): {case.title[:40]}...'')\n        for i, tag in enumerate(tags, 1):\n            print(f''  {i}. {tag}'')\n\")",
      "Bash(./venv/bin/pip install psutil)",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\nimport psycopg2\n\napp = create_app(''config'')\nwith app.app_context():\n    db_url = app.config.get(''DATABASE_URL'', os.environ.get(''DATABASE_URL''))\n    print(f''Database URL: {db_url}'')\n    \n    try:\n        conn = psycopg2.connect(db_url)\n        cur = conn.cursor()\n        \n        cur.execute(''''''\n            SELECT table_name \n            FROM information_schema.tables \n            WHERE table_schema=''public''\n            ORDER BY table_name;\n        '''''')\n        tables = [row[0] for row in cur.fetchall()]\n        print(f''Found {len(tables)} tables:'')\n        for table in tables[:10]:  # Show first 10\n            print(f''  - {table}'')\n        if len(tables) > 10:\n            print(f''  ... and {len(tables) - 10} more'')\n        \n        conn.close()\n    except Exception as e:\n        print(f''Error: {e}'')\n\")",
      "Bash(export PGPASSWORD=PASS)",
      "Bash(SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app, db\nfrom app.models.scenario import Scenario\nfrom app.models.wizard import WizardStep\n\napp = create_app()\nwith app.app_context():\n    scenario = Scenario.query.get(1)\n    if scenario:\n        print(f''Scenario 1: {scenario.name}'')\n        print(f''Description: {scenario.description[:100]}...'')\n        \n        steps = WizardStep.query.filter_by(scenario_id=1).order_by(WizardStep.step_number).all()\n        print(f''Wizard steps: {len(steps)}'')\n        \n        for step in steps[:3]:\n            print(f''  Step {step.step_number}: {step.step_type} - {step.title[:50]}...'')\n            if hasattr(step, ''options'') and step.options:\n                print(f''    Options: {len(step.options)}'')\n    else:\n        print(''Scenario 1 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''ENHANCED_SCENARIO_GENERATION''] = ''true''  # Enable enhanced generation\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.scenario_pipeline.scenario_generation_phase_a import DirectScenarioPipelineService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    # Test with case 7 (which user wants to look like scenario 1)\n    case = Document.query.get(7)\n    if case:\n        print(f''üß™ TESTING: Enhanced scenario generation for Case {case.id}'')\n        print(f''Title: {case.title}'')\n        print()\n        \n        try:\n            # Initialize enhanced pipeline\n            pipeline = DirectScenarioPipelineService()\n            print(f''‚úÖ Pipeline initialized, enhanced_enabled: {pipeline.enhanced_enabled}'')\n            \n            # Generate enhanced scenario\n            result = pipeline.generate(case, overwrite=True)\n            \n            print(f''‚úÖ Generation completed!'')\n            print(f''Pipeline version: {result.get(\"\"pipeline_version\"\")}'')\n            print(f''Events: {result.get(\"\"stats\"\", {}).get(\"\"event_count\"\", 0)}'')\n            print(f''Decisions: {result.get(\"\"stats\"\", {}).get(\"\"decision_count\"\", 0)}'')\n            \n            if ''wizard_scenario_id'' in result:\n                print(f''üéÆ Interactive wizard scenario created: {result[\"\"wizard_scenario_id\"\"]}'')\n                print(f''üîó Wizard URL: {result[\"\"wizard_url\"\"]}'')\n                print()\n                print(f''‚ú® SUCCESS: Case 7 now has an interactive wizard scenario!'')\n                print(f''   Access it at: http://localhost:3333/scenarios/{result[\"\"wizard_scenario_id\"\"]}'')\n            else:\n                if ''wizard_creation_error'' in result:\n                    print(f''‚ùå Wizard creation failed: {result[\"\"wizard_creation_error\"\"]}'')\n                else:\n                    print(''‚ö†Ô∏è  Wizard scenario ID not found in result'')\n                    \n        except Exception as e:\n            print(f''‚ùå Error: {e}'')\n            import traceback\n            traceback.print_exc()\n    else:\n        print(''‚ùå Case 7 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.scenario import Scenario\nfrom app.models.wizard import WizardStep\n\napp = create_app(''config'')\n\nwith app.app_context():\n    # Check the created wizard scenario\n    scenario = Scenario.query.get(8)\n    if scenario:\n        print(f''üéÆ WIZARD SCENARIO {scenario.id}'')\n        print(f''Name: {scenario.name}'')\n        print(f''Description: {scenario.description}'')\n        print(f''World ID: {scenario.world_id}'')\n        \n        if scenario.scenario_metadata:\n            print(f''Source case ID: {scenario.scenario_metadata.get(\"\"source_case_id\"\")}'')\n            print(f''Generation method: {scenario.scenario_metadata.get(\"\"generation_method\"\")}'')\n            print(f''Generated at: {scenario.scenario_metadata.get(\"\"generated_at\"\")}'')\n        \n        # Check wizard steps\n        steps = WizardStep.query.filter_by(scenario_id=scenario.id).order_by(WizardStep.step_number).all()\n        print(f''\\nWizard steps: {len(steps)}'')\n        for step in steps:\n            print(f''  Step {step.step_number}: {step.step_type} - \"\"{step.title}\"\"'')\n            if step.step_metadata:\n                if step.step_type == ''decision'':\n                    options = step.step_metadata.get(''options'', [])\n                    print(f''    {len(options)} options available'')\n        \n        print(f''\\n‚úÖ Wizard scenario is ready!'')\n        print(f''üîó Access at: http://localhost:3333/scenarios/8'')\n        \n    else:\n        print(''‚ùå Wizard scenario 8 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''ENHANCED_SCENARIO_GENERATION''] = ''true''\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.scenario_pipeline.scenario_generation_phase_a import DirectScenarioPipelineService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    # Test with case 7 again\n    case = Document.query.get(7)\n    if case:\n        print(f''üîÑ RETESTING: Enhanced scenario generation for Case {case.id}'')\n        \n        try:\n            pipeline = DirectScenarioPipelineService()\n            result = pipeline.generate(case, overwrite=True)\n            \n            print(f''‚úÖ Generation completed!'')\n            print(f''Events: {result.get(\"\"stats\"\", {}).get(\"\"event_count\"\", 0)}'')\n            print(f''Timeline events: {result.get(\"\"stats\"\", {}).get(\"\"timeline_events\"\", 0)}'')\n            print(f''Decisions: {result.get(\"\"stats\"\", {}).get(\"\"decision_count\"\", 0)}'')\n            print(f''Participants: {result.get(\"\"stats\"\", {}).get(\"\"participants_count\"\", 0)}'')\n            \n            if ''wizard_scenario_id'' in result:\n                print(f''üéÆ Interactive wizard: {result[\"\"wizard_scenario_id\"\"]}'')\n                \n                # Check the wizard steps now\n                from app.models.wizard import WizardStep\n                steps = WizardStep.query.filter_by(scenario_id=result[\"\"wizard_scenario_id\"\"]).all()\n                print(f''Wizard steps created: {len(steps)}'')\n                \n                if len(steps) > 0:\n                    print(f''‚ú® SUCCESS: Full interactive wizard scenario is ready!'')\n                    print(f''üîó Access at: http://localhost:3333/scenarios/{result[\"\"wizard_scenario_id\"\"]}'')\n                else:\n                    print(f''‚ö†Ô∏è  Wizard created but no steps generated'')\n            else:\n                print(f''‚ùå No wizard scenario created'')\n                    \n        except Exception as e:\n            print(f''‚ùå Error: {e}'')\n    else:\n        print(''‚ùå Case 7 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''ENHANCED_SCENARIO_GENERATION''] = ''true''\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.scenario_pipeline.enhanced_llm_scenario_service import EnhancedLLMScenarioService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    case = Document.query.get(7)\n    if case:\n        print(f''üîç DEBUGGING LLM Response for Case {case.id}'')\n        \n        # Get case sections\n        metadata = case.doc_metadata or {}\n        sections = metadata.get(''sections'', {})\n        \n        print(f''Sections available: {list(sections.keys())}'')\n        \n        # Test just the LLM service directly\n        try:\n            enhanced_service = EnhancedLLMScenarioService()\n            result = enhanced_service.extract_semantic_timeline(sections, metadata)\n            \n            print(f''Timeline result keys: {list(result.keys())}'')\n            if ''error'' in result:\n                print(f''Error: {result[\"\"error\"\"]}'')\n        except Exception as e:\n            print(f''Exception: {e}'')\n    else:\n        print(''Case 7 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''ENHANCED_SCENARIO_GENERATION''] = ''true''\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.scenario_pipeline.scenario_generation_phase_a import DirectScenarioPipelineService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    case = Document.query.get(7)\n    if case:\n        print(f''üöÄ FINAL TEST: Enhanced scenario generation for Case {case.id}'')\n        \n        try:\n            pipeline = DirectScenarioPipelineService()\n            result = pipeline.generate(case, overwrite=True)\n            \n            print(f''‚úÖ Generation completed successfully!'')\n            print(f''Events: {result.get(\"\"stats\"\", {}).get(\"\"event_count\"\", 0)}'')\n            print(f''Timeline events: {result.get(\"\"stats\"\", {}).get(\"\"timeline_events\"\", 0)}'')\n            print(f''Decisions: {result.get(\"\"stats\"\", {}).get(\"\"decision_count\"\", 0)}'')\n            print(f''Participants: {result.get(\"\"stats\"\", {}).get(\"\"participants_count\"\", 0)}'')\n            \n            if ''wizard_scenario_id'' in result:\n                wizard_id = result[''wizard_scenario_id'']\n                print(f''üéÆ Interactive wizard: {wizard_id}'')\n                \n                # Check the wizard steps now\n                from app.models.wizard import WizardStep\n                steps = WizardStep.query.filter_by(scenario_id=wizard_id).order_by(WizardStep.step_number).all()\n                print(f''Wizard steps created: {len(steps)}'')\n                \n                for step in steps[:5]:  # Show first 5 steps\n                    print(f''  Step {step.step_number}: {step.step_type} - \"\"{step.title}\"\"'')\n                \n                if len(steps) > 0:\n                    print(f''\\nüéâ SUCCESS! Full interactive wizard scenario created!'')\n                    print(f''üîó Ready to play at: http://localhost:3333/scenarios/{wizard_id}'')\n                    print(f''üìã Case detail page: http://localhost:3333/cases/7'')\n                else:\n                    print(f''‚ö†Ô∏è  Wizard created but no steps generated'')\n            else:\n                print(f''‚ùå No wizard scenario created'')\n                    \n        except Exception as e:\n            print(f''‚ùå Error: {e}'')\n            import traceback\n            traceback.print_exc()\n    else:\n        print(''‚ùå Case 7 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''ENHANCED_SCENARIO_GENERATION''] = ''true''\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.scenario_pipeline.scenario_generation_phase_a import DirectScenarioPipelineService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    case = Document.query.get(7)\n    if case:\n        print(f''üîß TESTING FIXES: Enhanced scenario generation for Case {case.id}'')\n        \n        try:\n            pipeline = DirectScenarioPipelineService()\n            result = pipeline.generate(case, overwrite=True)\n            \n            print(f''‚úÖ Generation completed successfully!'')\n            print(f''Events: {result.get(\"\"stats\"\", {}).get(\"\"event_count\"\", 0)}'')\n            print(f''Timeline events: {result.get(\"\"stats\"\", {}).get(\"\"timeline_events\"\", 0)}'')  \n            print(f''Decisions: {result.get(\"\"stats\"\", {}).get(\"\"decision_count\"\", 0)}'')\n            print(f''Participants: {result.get(\"\"stats\"\", {}).get(\"\"participants_count\"\", 0)}'')\n            \n            if ''wizard_scenario_id'' in result:\n                wizard_id = result[''wizard_scenario_id'']\n                print(f''üéÆ Interactive wizard: {wizard_id}'')\n                \n                # Check the wizard steps now\n                from app.models.wizard import WizardStep\n                steps = WizardStep.query.filter_by(scenario_id=wizard_id).order_by(WizardStep.step_number).all()\n                print(f''Wizard steps created: {len(steps)}'')\n                \n                for step in steps[:3]:  # Show first 3 steps\n                    print(f''  Step {step.step_number}: {step.step_type} - \"\"{step.title}\"\"'')\n                    if step.step_type == ''decision'' and step.step_metadata:\n                        options = step.step_metadata.get(''options'', [])\n                        print(f''    -> {len(options)} decision options available'')\n                \n                if len(steps) > 0:\n                    print(f''\\nüéâ COMPLETE SUCCESS!'')\n                    print(f''‚ú® Interactive wizard scenario ready with {len(steps)} steps'')\n                    print(f''üîó Play at: http://localhost:3333/scenarios/{wizard_id}'')\n                    print(f''üìã Or view from case page: http://localhost:3333/cases/7'')\n                    \n                    # Show the user what they can do now\n                    print(f''\\nüéØ What was achieved:'')\n                    print(f''  - LLM extracted semantic timeline from case text'')\n                    print(f''  - Created interactive wizard steps with decisions'')  \n                    print(f''  - Generated decision options with ethical analysis'')\n                    print(f''  - Made Case 7 look like Scenario 1 (interactive wizard format)'')\n                    \n                else:\n                    print(f''‚ö†Ô∏è  Wizard created but no steps generated'')\n            else:\n                if ''wizard_creation_error'' in result:\n                    print(f''‚ùå Wizard creation failed: {result[\"\"wizard_creation_error\"\"]}'')\n                else:\n                    print(f''‚ùå No wizard scenario created'')\n                    \n        except Exception as e:\n            print(f''‚ùå Error: {e}'')\n            import traceback\n            traceback.print_exc()\n    else:\n        print(''‚ùå Case 7 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''ENHANCED_SCENARIO_GENERATION''] = ''true''\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.scenario_pipeline.scenario_generation_phase_a import DirectScenarioPipelineService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    case = Document.query.get(7)\n    if case:\n        print(f''üéØ FINAL TEST: Complete enhanced scenario generation for Case {case.id}'')\n        \n        try:\n            pipeline = DirectScenarioPipelineService()\n            result = pipeline.generate(case, overwrite=True)\n            \n            print(f''‚úÖ Generation completed successfully!'')\n            print(f''Timeline events: {result.get(\"\"stats\"\", {}).get(\"\"timeline_events\"\", 0)}'')  \n            print(f''Total events: {result.get(\"\"stats\"\", {}).get(\"\"event_count\"\", 0)}'')\n            print(f''Decisions: {result.get(\"\"stats\"\", {}).get(\"\"decision_count\"\", 0)}'')\n            print(f''Participants: {result.get(\"\"stats\"\", {}).get(\"\"participants_count\"\", 0)}'')\n            \n            if ''wizard_scenario_id'' in result:\n                wizard_id = result[''wizard_scenario_id'']\n                print(f''\\nüéÆ Interactive wizard scenario created: {wizard_id}'')\n                \n                # Check the wizard steps\n                from app.models.wizard import WizardStep\n                steps = WizardStep.query.filter_by(scenario_id=wizard_id).order_by(WizardStep.step_number).all()\n                print(f''Wizard steps: {len(steps)}'')\n                \n                event_steps = [s for s in steps if s.step_type == ''event'']\n                decision_steps = [s for s in steps if s.step_type == ''decision'']\n                \n                print(f''  - Event steps: {len(event_steps)}'')\n                print(f''  - Decision steps: {len(decision_steps)}'')\n                \n                # Show sample steps\n                if steps:\n                    print(f''\\nSample wizard steps:'')\n                    for i, step in enumerate(steps[:3]):\n                        print(f''  {step.step_number}. [{step.step_type.upper()}] {step.title}'')\n                        if step.step_type == ''decision'' and step.step_metadata:\n                            options = step.step_metadata.get(''options'', [])\n                            print(f''      -> {len(options)} decision options'')\n                \n                if len(steps) > 0:\n                    print(f''\\nüéâ COMPLETE SUCCESS!'')\n                    print(f''‚ú® Case 7 now has full interactive wizard with {len(steps)} steps'')\n                    print(f''üéÆ Play the scenario: http://localhost:3333/scenarios/{wizard_id}'')\n                    print(f''üìÑ View from case page: http://localhost:3333/cases/7'')\n                    print(f''\\nüéØ MISSION ACCOMPLISHED: Case 7 now looks like Scenario 1!'')\n                    \n                else:\n                    print(f''‚ö†Ô∏è  Wizard created but no steps generated'')\n            else:\n                if ''wizard_creation_error'' in result:\n                    print(f''‚ùå Wizard creation failed: {result[\"\"wizard_creation_error\"\"]}'')\n                else:\n                    print(f''‚ùå No wizard scenario ID found'')\n                    \n        except Exception as e:\n            print(f''‚ùå Error: {e}'')\n            import traceback\n            traceback.print_exc()\n    else:\n        print(''‚ùå Case 7 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\n\napp = create_app(''config'')\n\nwith app.app_context():\n    case = Document.query.get(7)\n    if case and case.doc_metadata:\n        print(''üîç CASE 7 METADATA STRUCTURE'')\n        \n        # Check sections structure\n        sections = case.doc_metadata.get(''sections'', {})\n        print(f''Sections available: {list(sections.keys())}'')\n        \n        for section_name, section_content in sections.items():\n            print(f''\\nSection: {section_name}'')\n            print(f''Type: {type(section_content)}'')\n            if isinstance(section_content, dict):\n                print(f''Keys: {list(section_content.keys())}'')\n                if ''text'' in section_content:\n                    print(f''Has .text: {len(section_content[\"\"text\"\"])} chars'')\n                if ''content'' in section_content:\n                    print(f''Has .content: {len(section_content[\"\"content\"\"])} chars'')\n            elif isinstance(section_content, str):\n                print(f''String content: {len(section_content)} chars'')\n            break  # Just check first section structure\n    else:\n        print(''Case 7 not found or no metadata'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\n\napp = create_app(''config'')\n\nwith app.app_context():\n    case = Document.query.get(7)\n    if case and case.doc_metadata:\n        latest = case.doc_metadata.get(''latest_scenario'', {})\n        print(''Latest scenario keys:'', list(latest.keys()))\n        if ''wizard_scenario_id'' in latest:\n            print(f''Wizard scenario ID: {latest[\"\"wizard_scenario_id\"\"]}'')\n        else:\n            print(''‚ùå No wizard_scenario_id in latest_scenario'')\n            \n        # Check if there are any versions with wizard_scenario_id\n        versions = case.doc_metadata.get(''scenario_versions'', [])\n        print(f''Total versions: {len(versions)}'')\n        for i, version in enumerate(versions[-3:], len(versions)-2):\n            if ''wizard_scenario_id'' in version:\n                print(f''Version {i}: has wizard_scenario_id = {version[\"\"wizard_scenario_id\"\"]}'')\n            else:\n                print(f''Version {i}: no wizard_scenario_id'')\n    else:\n        print(''Case 7 not found or no metadata'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''ENHANCED_SCENARIO_GENERATION''] = ''true''\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.scenario_pipeline.scenario_generation_phase_a import DirectScenarioPipelineService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    case = Document.query.get(7)\n    if case:\n        print(f''üéØ FINAL TEST: Complete enhanced scenario generation for Case {case.id}'')\n        \n        try:\n            pipeline = DirectScenarioPipelineService()\n            result = pipeline.generate(case, overwrite=True)\n            \n            print(f''‚úÖ Generation completed successfully!'')\n            print(f''Timeline events: {result.get(\"\"stats\"\", {}).get(\"\"timeline_events\"\", 0)}'')  \n            print(f''Total events: {result.get(\"\"stats\"\", {}).get(\"\"event_count\"\", 0)}'')\n            print(f''Decisions: {result.get(\"\"stats\"\", {}).get(\"\"decision_count\"\", 0)}'')\n            print(f''Participants: {result.get(\"\"stats\"\", {}).get(\"\"participants_count\"\", 0)}'')\n            \n            if ''wizard_scenario_id'' in result:\n                wizard_id = result[''wizard_scenario_id'']\n                print(f''\\nüéÆ Interactive wizard scenario created: {wizard_id}'')\n                \n                # Check the wizard steps\n                from app.models.wizard import WizardStep\n                steps = WizardStep.query.filter_by(scenario_id=wizard_id).order_by(WizardStep.step_number).all()\n                print(f''Wizard steps: {len(steps)}'')\n                \n                event_steps = [s for s in steps if s.step_type == ''event'']\n                decision_steps = [s for s in steps if s.step_type == ''decision'']\n                \n                print(f''  - Event steps: {len(event_steps)}'')\n                print(f''  - Decision steps: {len(decision_steps)}'')\n                \n                if len(steps) > 0:\n                    print(f''\\nüéâ COMPLETE SUCCESS!'')\n                    print(f''‚ú® Case 7 now has full interactive wizard with {len(steps)} steps'')\n                    print(f''üéÆ Play the scenario: http://localhost:3333/scenarios/{wizard_id}'')\n                    print(f''üìÑ View from case page: http://localhost:3333/cases/7'')\n                    print(f''\\nüéØ MISSION ACCOMPLISHED: Case 7 now looks like Scenario 1!'')\n                    \n                else:\n                    print(f''‚ö†Ô∏è  Wizard created but no steps generated'')\n            else:\n                if ''wizard_creation_error'' in result:\n                    print(f''‚ùå Wizard creation failed: {result[\"\"wizard_creation_error\"\"]}'')\n                else:\n                    print(f''‚ùå No wizard scenario ID found'')\n                    \n        except Exception as e:\n            print(f''‚ùå Error: {e}'')\n            import traceback\n            traceback.print_exc()\n    else:\n        print(''‚ùå Case 7 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''ENHANCED_SCENARIO_GENERATION''] = ''true''\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.scenario_pipeline.scenario_generation_phase_a import DirectScenarioPipelineService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    case = Document.query.get(7)\n    if case:\n        print(f''üéØ FINAL TEST: Complete enhanced scenario generation for Case {case.id}'')\n        \n        try:\n            pipeline = DirectScenarioPipelineService()\n            result = pipeline.generate(case, overwrite=True)\n            \n            print(f''‚úÖ Generation completed successfully!'')\n            print(f''Timeline events: {result.get(\"\"stats\"\", {}).get(\"\"timeline_events\"\", 0)}'')  \n            print(f''Total events: {result.get(\"\"stats\"\", {}).get(\"\"event_count\"\", 0)}'')\n            print(f''Decisions: {result.get(\"\"stats\"\", {}).get(\"\"decision_count\"\", 0)}'')\n            print(f''Participants: {result.get(\"\"stats\"\", {}).get(\"\"participants_count\"\", 0)}'')\n            \n            if ''wizard_scenario_id'' in result:\n                wizard_id = result[''wizard_scenario_id'']\n                print(f''\\nüéÆ Interactive wizard scenario created: {wizard_id}'')\n                \n                # Check the wizard steps\n                from app.models.wizard import WizardStep\n                steps = WizardStep.query.filter_by(scenario_id=wizard_id).order_by(WizardStep.step_number).all()\n                print(f''Wizard steps: {len(steps)}'')\n                \n                event_steps = [s for s in steps if s.step_type == ''event'']\n                decision_steps = [s for s in steps if s.step_type == ''decision'']\n                \n                print(f''  - Event steps: {len(event_steps)}'')\n                print(f''  - Decision steps: {len(decision_steps)}'')\n                \n                if len(steps) > 0:\n                    print(f''\\nüéâ COMPLETE SUCCESS!'')\n                    print(f''‚ú® Case 7 now has full interactive wizard with {len(steps)} steps'')\n                    print(f''üéÆ Play the scenario: http://localhost:3333/scenarios/{wizard_id}'')\n                    print(f''üìÑ View from case page: http://localhost:3333/cases/7'')\n                    print(f''\\nüéØ MISSION ACCOMPLISHED: Case 7 now looks like Scenario 1!'')\n                    \n                else:\n                    print(f''‚ö†Ô∏è  Wizard created but no steps generated'')\n            else:\n                if ''wizard_creation_error'' in result:\n                    print(f''‚ùå Wizard creation failed: {result[\"\"wizard_creation_error\"\"]}'')\n                else:\n                    print(f''‚ùå No wizard scenario ID found'')\n                    \n        except Exception as e:\n            print(f''‚ùå Error: {e}'')\n            import traceback\n            traceback.print_exc()\n    else:\n        print(''‚ùå Case 7 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.scenario import Scenario\nfrom app.models.character import Character\nfrom app.models.resource import Resource\nfrom app.models.event import Event\nfrom app.models.action import Action\n\napp = create_app(''config'')\n\nwith app.app_context():\n    # Check scenario 7 structure\n    scenario = Scenario.query.get(7)\n    if scenario:\n        print(''üìã SCENARIO 7 STRUCTURE'')\n        print(f''Name: {scenario.name}'')\n        print(f''Description: {scenario.description}'')\n        \n        # Check characters\n        characters = Character.query.filter_by(scenario_id=7).all()\n        print(f''\\nüë• Characters: {len(characters)}'')\n        for char in characters[:3]:\n            print(f''  - {char.name} ({char.role})'')\n        \n        # Check resources  \n        resources = Resource.query.filter_by(scenario_id=7).all()\n        print(f''\\nüîß Resources: {len(resources)}'')\n        for res in resources[:3]:\n            print(f''  - {res.name} ({res.resource_type})'')\n        \n        # Check events\n        events = Event.query.filter_by(scenario_id=7).all()\n        print(f''\\nüìÖ Events: {len(events)}'')\n        for event in events[:3]:\n            print(f''  - {event.description[:50]}...'')\n        \n        # Check actions (decisions)\n        actions = Action.query.filter_by(scenario_id=7).all()\n        print(f''\\n‚ö° Actions/Decisions: {len(actions)}'')\n        for action in actions[:3]:\n            options_count = len(action.options.split(''||'')) if action.options else 0\n            print(f''  - {action.name}: {options_count} options'')\n            \n    else:\n        print(''‚ùå Scenario 7 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\n\napp = create_app(''config'')\n\nwith app.app_context():\n    from app.models import db\n    \n    # Check what tables exist\n    inspector = db.inspect(db.engine)\n    tables = inspector.get_table_names()\n    \n    print(''üìä DATABASE TABLES:'')\n    scenario_related = [t for t in tables if any(word in t for word in [''scenario'', ''character'', ''resource'', ''event'', ''action'', ''decision''])]\n    for table in sorted(scenario_related):\n        print(f''  - {table}'')\n        \n    # Let''s check the actual scenario 7 data\n    print(''\\nüîç SCENARIO 7 DATA:'')\n    result = db.session.execute(''SELECT * FROM scenarios WHERE id = 7'')\n    scenario = result.fetchone()\n    if scenario:\n        print(f''Scenario: {scenario.name if hasattr(scenario, \"\"name\"\") else \"\"N/A\"\"}'')\n        \n    # Check for actions table\n    if ''actions'' in tables:\n        print(''\\n‚ö° ACTIONS TABLE EXISTS'')\n        actions = db.session.execute(''SELECT id, name, scenario_id FROM actions WHERE scenario_id = 7 LIMIT 3'').fetchall()\n        for action in actions:\n            print(f''  - Action {action.id}: {action.name}'')\n    \n    # Check for decisions table  \n    if ''decisions'' in tables:\n        print(''\\nüìã DECISIONS TABLE EXISTS'')\n        decisions = db.session.execute(''SELECT id, description, scenario_id FROM decisions WHERE scenario_id = 7 LIMIT 3'').fetchall()\n        for decision in decisions:\n            print(f''  - Decision {decision.id}: {decision.description}'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''ENHANCED_SCENARIO_GENERATION''] = ''true''\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.scenario_pipeline.scenario_generation_phase_a import DirectScenarioPipelineService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    case = Document.query.get(7)\n    if case:\n        print(f''üöÄ TESTING: Enhanced scenario generation for Case {case.id}'')\n        print(f''Title: {case.title}'')\n        \n        try:\n            pipeline = DirectScenarioPipelineService()\n            result = pipeline.generate(case, overwrite=True)\n            \n            print(f''‚úÖ Generation completed successfully!'')\n            print(f''Timeline events: {result.get(\"\"stats\"\", {}).get(\"\"timeline_events\"\", 0)}'')  \n            print(f''Total events: {result.get(\"\"stats\"\", {}).get(\"\"event_count\"\", 0)}'')\n            print(f''Decisions: {result.get(\"\"stats\"\", {}).get(\"\"decision_count\"\", 0)}'')\n            print(f''Participants: {result.get(\"\"stats\"\", {}).get(\"\"participants_count\"\", 0)}'')\n            \n            if ''scenario_id'' in result:\n                scenario_id = result[''scenario_id'']\n                print(f''\\nüéÆ Enhanced scenario created: {scenario_id}'')\n                \n                # Check the created models\n                from app.models.scenario import Scenario\n                scenario = Scenario.query.get(scenario_id)\n                if scenario:\n                    print(f''Scenario: {scenario.name}'')\n                    print(f''Characters: {len(scenario.characters)}'')\n                    print(f''Resources: {len(scenario.resources)}'')\n                    print(f''Events: {len(scenario.events)}'')\n                    print(f''Actions: {len(scenario.actions)}'')\n                    \n                    # Check ontology summary\n                    if scenario.scenario_metadata and ''ontology_summary'' in scenario.scenario_metadata:\n                        ontology = scenario.scenario_metadata[''ontology_summary'']\n                        print(f''\\nOntology categories:'')\n                        for category, items in ontology.items():\n                            print(f''  {category}: {len(items)} items'')\n                    \n                    print(f''\\nüéâ SUCCESS! Enhanced scenario ready!'')\n                    print(f''üîó View at: http://localhost:3333/scenarios/{scenario_id}'')\n                    print(f''üìÑ Case page: http://localhost:3333/cases/7'')\n                else:\n                    print(f''‚ùå Scenario {scenario_id} not found in database'')\n            else:\n                if ''model_creation_error'' in result:\n                    print(f''‚ùå Model creation failed: {result[\"\"model_creation_error\"\"]}'')\n                else:\n                    print(f''‚ùå No scenario ID found in result'')\n                    \n        except Exception as e:\n            print(f''‚ùå Error: {e}'')\n            import traceback\n            traceback.print_exc()\n    else:\n        print(''‚ùå Case 7 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''ENHANCED_SCENARIO_GENERATION''] = ''true''\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.scenario_pipeline.scenario_generation_phase_a import DirectScenarioPipelineService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    case = Document.query.get(7)\n    if case:\n        print(f''üöÄ TESTING: Enhanced scenario generation for Case {case.id}'')\n        print(f''Title: {case.title}'')\n        \n        try:\n            pipeline = DirectScenarioPipelineService()\n            result = pipeline.generate(case, overwrite=True)\n            \n            print(f''‚úÖ Generation completed successfully!'')\n            print(f''Pipeline version: {result.get(\"\"pipeline_version\"\")}'')\n            print(f''Timeline events: {result.get(\"\"stats\"\", {}).get(\"\"timeline_events\"\", 0)}'')  \n            print(f''Total events: {result.get(\"\"stats\"\", {}).get(\"\"event_count\"\", 0)}'')\n            print(f''Decisions: {result.get(\"\"stats\"\", {}).get(\"\"decision_count\"\", 0)}'')\n            print(f''Participants: {result.get(\"\"stats\"\", {}).get(\"\"participants_count\"\", 0)}'')\n            \n            if ''scenario_id'' in result:\n                scenario_id = result[''scenario_id'']\n                print(f''\\nüéÆ Enhanced scenario created: {scenario_id}'')\n                \n                # Check the created models\n                from app.models.scenario import Scenario\n                scenario = Scenario.query.get(scenario_id)\n                if scenario:\n                    print(f''Scenario: {scenario.name}'')\n                    print(f''Characters: {len(scenario.characters)}'')\n                    print(f''Resources: {len(scenario.resources)}'')\n                    print(f''Events: {len(scenario.events)}'')\n                    print(f''Actions: {len(scenario.actions)}'')\n                    \n                    # Check decision actions\n                    decision_actions = [a for a in scenario.actions if a.is_decision]\n                    print(f''Decision actions: {len(decision_actions)}'')\n                    \n                    # Check ontology summary\n                    if scenario.scenario_metadata and ''ontology_summary'' in scenario.scenario_metadata:\n                        ontology = scenario.scenario_metadata[''ontology_summary'']\n                        print(f''\\nOntology categories:'')\n                        for category, items in ontology.items():\n                            print(f''  {category}: {len(items)} items'')\n                    \n                    print(f''\\nüéâ SUCCESS! Enhanced scenario ready!'')\n                    print(f''üîó View at: http://localhost:3333/scenarios/{scenario_id}'')\n                    print(f''üìÑ Case page: http://localhost:3333/cases/7'')\n                else:\n                    print(f''‚ùå Scenario {scenario_id} not found in database'')\n            else:\n                if ''model_creation_error'' in result:\n                    print(f''‚ùå Model creation failed: {result[\"\"model_creation_error\"\"]}'')\n                else:\n                    print(f''‚ùå No scenario ID found in result'')\n                    print(f''Result keys: {list(result.keys())}'')\n                    \n        except Exception as e:\n            print(f''‚ùå Error: {e}'')\n            import traceback\n            traceback.print_exc()\n    else:\n        print(''‚ùå Case 7 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\n\napp = create_app(''config'')\n\nwith app.app_context():\n    case = Document.query.get(7)\n    if case and case.doc_metadata:\n        latest = case.doc_metadata.get(''latest_scenario'', {})\n        print(''‚úÖ CASE 7 SCENARIO STATUS:'')\n        print(f''  Has scenario data: {\"\"scenario_id\"\" in latest}'')\n        if ''scenario_id'' in latest:\n            print(f''  Scenario ID: {latest[\"\"scenario_id\"\"]}'')\n            print(f''  Pipeline: {latest.get(\"\"pipeline_version\"\", \"\"unknown\"\")}'')\n            print(f''  Events: {latest.get(\"\"stats\"\", {}).get(\"\"event_count\"\", 0)}'')\n            print(f''  Decisions: {latest.get(\"\"stats\"\", {}).get(\"\"decision_count\"\", 0)}'')\n            \n            # Check if scenario exists in database\n            from app.models.scenario import Scenario\n            scenario = Scenario.query.get(latest[''scenario_id''])\n            if scenario:\n                print(f''  ‚úÖ Scenario exists in database'')\n                print(f''  Characters: {len(scenario.characters)}'')\n                print(f''  Resources: {len(scenario.resources)}'')\n                print(f''  Events: {len(scenario.events)}'')\n                print(f''  Actions: {len(scenario.actions)}'')\n            else:\n                print(f''  ‚ùå Scenario missing from database'')\n        else:\n            print(''  ‚ùå No scenario ID found'')\n    else:\n        print(''‚ùå Case 7 not found or no metadata'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\n\napp = create_app(''config'')\n\nwith app.app_context():\n    # Find a case without a scenario\n    cases = Document.query.filter_by(document_type=''case_study'').all()\n    cases_without_scenarios = []\n    \n    for case in cases[:10]:  # Check first 10 cases\n        has_scenario = (case.doc_metadata and \n                       case.doc_metadata.get(''latest_scenario'', {}).get(''scenario_id''))\n        if not has_scenario:\n            cases_without_scenarios.append(case)\n    \n    print(f''üìä SCENARIO COVERAGE:'')\n    print(f''  Cases checked: 10'')\n    print(f''  Cases without scenarios: {len(cases_without_scenarios)}'')\n    \n    if cases_without_scenarios:\n        print(f''\\nüìù CASES WITHOUT SCENARIOS:'')\n        for case in cases_without_scenarios[:3]:\n            print(f''  Case {case.id}: {case.title[:50]}...'')\n            print(f''    URL: http://localhost:3333/cases/{case.id}'')\n    else:\n        print(f''\\n‚úÖ All checked cases have scenarios!'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\n\napp = create_app(''config'')\n\nprint(''‚úÖ SUMMARY OF UI CHANGES:'')\nprint('''')\nprint(''üì± CASE DETAIL PAGE UPDATES:'')\nprint(''  - Removed \"\"Direct Scenario Timeline\"\" section'')\nprint(''  - Removed \"\"Ontology Analysis\"\" section'')\nprint(''  - Simplified to single \"\"Scenario\"\" section'')\nprint(''  - Button text changed to \"\"Generate Scenario\"\" and \"\"View Scenario\"\"'')\nprint(''  - Removed toggle enhancement mode (always uses enhanced)'')\nprint(''  - One scenario per case with regeneration capability'')\nprint('''')\nprint(''üéØ SCENARIO TEMPLATE UPDATES:'')\nprint(''  - Added \"\"Ontology Categories\"\" section showing all 9 categories'')\nprint(''  - Role, Principle, Obligation, State, Resource, Action, Event, Capability, Constraint'')\nprint(''  - Beautiful card layout with icons for each category'')\nprint('''')\nprint(''üîß BACKEND UPDATES:'')\nprint(''  - Created EnhancedScenarioModelGenerator service'')\nprint(''  - Generates proper Character, Resource, Event, Action database records'')\nprint(''  - Always uses enhanced LLM pipeline by default'')\nprint(''  - Regeneration replaces existing scenario (one per case)'')\nprint('''')\nprint(''üìä TEST STATUS:'')\nprint(''  - Case 7: Has enhanced scenario #15 with full models ‚úÖ'')\nprint(''  - Cases 13,14,15: Ready for scenario generation ‚úÖ'')\nprint(''  - UI updated and JavaScript handlers fixed ‚úÖ'')\nprint('''')\nprint(''üéâ READY TO USE:'')\nprint(''  - Visit http://localhost:3333/cases/7 - should show \"\"View Scenario\"\" button'')\nprint(''  - Visit http://localhost:3333/scenarios/15 - should show all 9 ontology categories'')\nprint(''  - Visit http://localhost:3333/cases/13 - should show \"\"Generate Scenario\"\" button'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''ENHANCED_SCENARIO_GENERATION''] = ''true''\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.scenario_pipeline.scenario_generation_phase_a import DirectScenarioPipelineService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    # Test with case 12 that user mentioned\n    case = Document.query.get(12)\n    if case:\n        print(f''üöÄ TESTING: Scenario generation for Case {case.id}'')\n        print(f''Title: {case.title}'')\n        \n        try:\n            pipeline = DirectScenarioPipelineService()\n            result = pipeline.generate(case, overwrite=True)\n            \n            print(f''\\n‚úÖ Generation completed!'')\n            print(f''Pipeline version: {result.get(\"\"pipeline_version\"\")}'')\n            print(f''Events: {result.get(\"\"stats\"\", {}).get(\"\"event_count\"\", 0)}'')\n            print(f''Decisions: {result.get(\"\"stats\"\", {}).get(\"\"decision_count\"\", 0)}'')\n            \n            if ''scenario_id'' in result:\n                scenario_id = result[''scenario_id'']\n                print(f''\\nüéÆ Scenario created: {scenario_id}'')\n                \n                # Check the created models\n                from app.models.scenario import Scenario\n                scenario = Scenario.query.get(scenario_id)\n                if scenario:\n                    print(f''Scenario name: {scenario.name}'')\n                    print(f''Characters: {len(scenario.characters)}'')\n                    print(f''Resources: {len(scenario.resources)}'')\n                    print(f''Events: {len(scenario.events)}'')\n                    print(f''Actions: {len(scenario.actions)}'')\n                    \n                    print(f''\\nüéâ SUCCESS! Scenario ready at http://localhost:3333/scenarios/{scenario_id}'')\n                else:\n                    print(f''‚ùå Scenario {scenario_id} not found in database'')\n            else:\n                if ''model_creation_error'' in result:\n                    print(f''‚ùå Model creation failed: {result[\"\"model_creation_error\"\"]}'')\n                else:\n                    print(f''‚ùå No scenario ID found - scenario data generated but models not created'')\n                    \n            # Check MCP status\n            if result.get(''ontology_enrichment_status'') == ''failed'':\n                print(f''\\n‚ö†Ô∏è  MCP WARNING: {result.get(\"\"ontology_enrichment_error\"\")}'')\n                print(''‚ö†Ô∏è  Running without full ontology integration'')\n                    \n        except Exception as e:\n            print(f''‚ùå Error: {e}'')\n            import traceback\n            traceback.print_exc()\n    else:\n        print(''‚ùå Case 12 not found'')\n\")",
      "WebFetch(domain:www.w3.org)",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nfrom app import create_app, db\n\napp = create_app(''config'')\nwith app.app_context():\n    # Check if characters table exists and get count\n    try:\n        result = db.session.execute(''SELECT COUNT(*) as count FROM characters'').fetchone()\n        print(f''Characters table: {result[0]} records'')\n        \n        # Check table structure\n        result = db.session.execute(\"\"\"\"\"\"\n            SELECT column_name, data_type \n            FROM information_schema.columns \n            WHERE table_name = ''characters'' \n            ORDER BY ordinal_position\n        \"\"\"\"\"\").fetchall()\n        print(''Characters table structure:'')\n        for row in result:\n            print(f''  {row[0]}: {row[1]}'')\n    except Exception as e:\n        print(f''Error checking characters table: {e}'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nfrom app import create_app, db\n\napp = create_app(''config'')\nwith app.app_context():\n    try:\n        # Read and execute the migration script\n        with open(''scripts/add_bfo_fields_phase2a.sql'', ''r'') as f:\n            migration_sql = f.read()\n        \n        # Split into individual statements and execute them\n        statements = [stmt.strip() for stmt in migration_sql.split('';'') if stmt.strip() and not stmt.strip().startswith(''--'')]\n        \n        for stmt in statements:\n            if stmt.upper().startswith(''BEGIN'') or stmt.upper().startswith(''COMMIT''):\n                continue  # Skip transaction control in this context\n            if stmt.strip():\n                print(f''Executing: {stmt[:50]}...'')\n                try:\n                    result = db.session.execute(stmt)\n                    if result.returns_rows:\n                        rows = result.fetchall()\n                        for row in rows:\n                            print(f''  {row}'')\n                except Exception as e:\n                    print(f''  Error: {e}'')\n        \n        db.session.commit()\n        print(''‚úÖ Migration completed successfully!'')\n        \n    except Exception as e:\n        print(f''‚ùå Error running migration: {e}'')\n        db.session.rollback()\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nfrom app import create_app, db\nfrom sqlalchemy import text\n\napp = create_app(''config'')\nwith app.app_context():\n    try:\n        print(''üöÄ Running BFO fields migration...'')\n        \n        # Add fields to characters table\n        try:\n            db.session.execute(text(''ALTER TABLE characters ADD COLUMN IF NOT EXISTS bfo_class VARCHAR(255) DEFAULT \\''BFO_0000040\\''''))\n            db.session.execute(text(''ALTER TABLE characters ADD COLUMN IF NOT EXISTS proethica_category VARCHAR(50) DEFAULT \\''role\\''''))\n            db.session.execute(text(''ALTER TABLE characters ADD COLUMN IF NOT EXISTS ontology_uri VARCHAR(500)''))\n            print(''‚úÖ Added BFO fields to characters table'')\n        except Exception as e:\n            print(f''‚ö†Ô∏è  Characters table fields: {e}'')\n        \n        # Add fields to events table\n        try:\n            db.session.execute(text(''ALTER TABLE events ADD COLUMN IF NOT EXISTS bfo_class VARCHAR(255) DEFAULT \\''BFO_0000015\\''''))\n            db.session.execute(text(''ALTER TABLE events ADD COLUMN IF NOT EXISTS proethica_category VARCHAR(50) DEFAULT \\''event\\''''))\n            db.session.execute(text(''ALTER TABLE events ADD COLUMN IF NOT EXISTS ontology_uri VARCHAR(500)''))\n            print(''‚úÖ Added BFO fields to events table'')\n        except Exception as e:\n            print(f''‚ö†Ô∏è  Events table fields: {e}'')\n        \n        # Add fields to actions table\n        try:\n            db.session.execute(text(''ALTER TABLE actions ADD COLUMN IF NOT EXISTS bfo_class VARCHAR(255) DEFAULT \\''BFO_0000015\\''''))\n            db.session.execute(text(''ALTER TABLE actions ADD COLUMN IF NOT EXISTS proethica_category VARCHAR(50) DEFAULT \\''action\\''''))\n            db.session.execute(text(''ALTER TABLE actions ADD COLUMN IF NOT EXISTS ontology_uri VARCHAR(500)''))\n            db.session.execute(text(''ALTER TABLE actions ADD COLUMN IF NOT EXISTS is_decision BOOLEAN DEFAULT false''))\n            print(''‚úÖ Added BFO fields to actions table'')\n        except Exception as e:\n            print(f''‚ö†Ô∏è  Actions table fields: {e}'')\n        \n        db.session.commit()\n        print(''\\nüéâ Migration completed successfully!'')\n        \n        # Verify the changes\n        result = db.session.execute(text(\"\"\"\"\"\"\n            SELECT table_name, column_name, data_type, column_default \n            FROM information_schema.columns \n            WHERE table_name IN (''characters'', ''events'', ''actions'')\n            AND column_name IN (''bfo_class'', ''proethica_category'', ''ontology_uri'', ''is_decision'')\n            ORDER BY table_name, column_name\n        \"\"\"\"\"\"))\n        \n        print(''\\nüìä Verification - New BFO fields:'')\n        for row in result:\n            print(f''  {row[0]}.{row[1]}: {row[2]} (default: {row[3]})'')\n        \n    except Exception as e:\n        print(f''‚ùå Error running migration: {e}'')\n        db.session.rollback()\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''ENHANCED_SCENARIO_GENERATION''] = ''true''\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.scenario_pipeline.scenario_generation_phase_a import DirectScenarioPipelineService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    # Test with case 12 that user mentioned\n    case = Document.query.get(12)\n    if case:\n        print(f''üöÄ TESTING: Enhanced scenario generation with BFO fields for Case {case.id}'')\n        print(f''Title: {case.title}'')\n        \n        try:\n            pipeline = DirectScenarioPipelineService()\n            result = pipeline.generate(case, overwrite=True)\n            \n            print(f''\\n‚úÖ Generation completed!'')\n            print(f''Pipeline version: {result.get(\"\"pipeline_version\"\")}'')\n            print(f''Events: {result.get(\"\"stats\"\", {}).get(\"\"event_count\"\", 0)}'')\n            print(f''Decisions: {result.get(\"\"stats\"\", {}).get(\"\"decision_count\"\", 0)}'')\n            \n            if ''scenario_id'' in result:\n                scenario_id = result[''scenario_id'']\n                print(f''\\nüéÆ Enhanced scenario created: {scenario_id}'')\n                \n                # Check the created models for BFO fields\n                from app.models.scenario import Scenario\n                scenario = Scenario.query.get(scenario_id)\n                if scenario:\n                    print(f''Scenario name: {scenario.name}'')\n                    print(f''Characters: {len(scenario.characters)}'')\n                    print(f''Events: {len(scenario.events)}'')\n                    print(f''Actions: {len(scenario.actions)}'')\n                    \n                    # Check BFO fields in first character\n                    if scenario.characters:\n                        char = scenario.characters[0]\n                        print(f''\\nüß¨ BFO fields in first character ({char.name}):'')\n                        print(f''  bfo_class: {char.bfo_class}'')\n                        print(f''  proethica_category: {char.proethica_category}'')\n                        print(f''  ontology_uri: {char.ontology_uri}'')\n                    \n                    # Check BFO fields in first event\n                    if scenario.events:\n                        event = scenario.events[0]\n                        print(f''\\nüìÖ BFO fields in first event:'')\n                        print(f''  bfo_class: {event.bfo_class}'')\n                        print(f''  proethica_category: {event.proethica_category}'')\n                        print(f''  ontology_uri: {event.ontology_uri}'')\n                    \n                    # Check BFO fields in first action\n                    if scenario.actions:\n                        action = scenario.actions[0]\n                        print(f''\\n‚ö° BFO fields in first action ({action.name}):'')\n                        print(f''  bfo_class: {action.bfo_class}'')\n                        print(f''  proethica_category: {action.proethica_category}'')\n                        print(f''  ontology_uri: {action.ontology_uri}'')\n                        print(f''  is_decision: {action.is_decision}'')\n                    \n                    print(f''\\nüéâ SUCCESS! Enhanced scenario with BFO ontology fields ready!'')\n                    print(f''üîó View at: http://localhost:3333/scenarios/{scenario_id}'')\n                    print(f''üìÑ Case page: http://localhost:3333/cases/12'')\n                else:\n                    print(f''‚ùå Scenario {scenario_id} not found in database'')\n            else:\n                print(f''‚ùå No scenario ID found in result'')\n                print(f''Result keys: {list(result.keys())}'')\n                    \n        except Exception as e:\n            print(f''‚ùå Error: {e}'')\n            import traceback\n            traceback.print_exc()\n    else:\n        print(''‚ùå Case 12 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''ENHANCED_SCENARIO_GENERATION''] = ''true''\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.scenario_pipeline.scenario_generation_phase_a import DirectScenarioPipelineService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    # Test with case 12 that user mentioned\n    case = Document.query.get(12)\n    if case:\n        print(f''üöÄ TESTING: Enhanced scenario generation with BFO fields for Case {case.id}'')\n        print(f''Title: {case.title}'')\n        \n        try:\n            pipeline = DirectScenarioPipelineService()\n            result = pipeline.generate(case, overwrite=True)\n            \n            print(f''\\n‚úÖ Generation completed!'')\n            print(f''Pipeline version: {result.get(\"\"pipeline_version\"\")}'')\n            print(f''Events: {result.get(\"\"stats\"\", {}).get(\"\"event_count\"\", 0)}'')\n            print(f''Decisions: {result.get(\"\"stats\"\", {}).get(\"\"decision_count\"\", 0)}'')\n            \n            if ''scenario_id'' in result:\n                scenario_id = result[''scenario_id'']\n                print(f''\\nüéÆ Enhanced scenario created: {scenario_id}'')\n                \n                # Check the created models for BFO fields\n                from app.models.scenario import Scenario\n                scenario = Scenario.query.get(scenario_id)\n                if scenario:\n                    print(f''Scenario name: {scenario.name}'')\n                    print(f''Characters: {len(scenario.characters)}'')\n                    print(f''Events: {len(scenario.events)}'')\n                    print(f''Actions: {len(scenario.actions)}'')\n                    \n                    # Check BFO fields in first character\n                    if scenario.characters:\n                        char = scenario.characters[0]\n                        print(f''\\nüß¨ BFO fields in first character ({char.name}):'')\n                        print(f''  bfo_class: {char.bfo_class}'')\n                        print(f''  proethica_category: {char.proethica_category}'')\n                        print(f''  ontology_uri: {char.ontology_uri}'')\n                    \n                    print(f''\\nüéâ SUCCESS! Enhanced scenario with BFO ontology fields ready!'')\n                    print(f''üîó View at: http://localhost:3333/scenarios/{scenario_id}'')\n                else:\n                    print(f''‚ùå Scenario {scenario_id} not found in database'')\n            else:\n                print(f''‚ùå No scenario ID found in result'')\n                    \n        except Exception as e:\n            print(f''‚ùå Error: {e}'')\n            import traceback\n            traceback.print_exc()\n    else:\n        print(''‚ùå Case 12 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nfrom app import create_app\nfrom app.models.scenario import Scenario\n\napp = create_app(''config'')\nwith app.app_context():\n    scenario = Scenario.query.get(20)  # The test scenario we just created\n    if scenario:\n        print(f''Scenario: {scenario.name}'')\n        print(f''Characters (should be Participants):'')\n        for char in scenario.characters:\n            print(f''  Name: {char.name}'')\n            print(f''  Role: {char.role}'')\n            print(f''  Role from role_from_role: {char.role_from_role.name if char.role_from_role else \"\"None\"\"}'')\n            print(f''  BFO class: {char.bfo_class}'')\n            print(f''  ProEthica category: {char.proethica_category}'')\n            print(f''  Ontology URI: {char.ontology_uri}'')\n            print(f''  Attributes: {char.attributes}'')\n            print(''---'')\n    else:\n        print(''Scenario 20 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nfrom app import create_app\nfrom app.models.document import Document\n\napp = create_app(''config'')\nwith app.app_context():\n    case = Document.query.get(12)  # Case that generated scenario 20\n    if case:\n        print(f''Case: {case.title}'')\n        \n        # Check if we have sections with role information\n        sections = case.doc_metadata.get(''sections'', {}) if case.doc_metadata else {}\n        \n        print(f''Available sections: {list(sections.keys())}'')\n        \n        # Look at the facts section which usually contains participant roles\n        if ''facts'' in sections:\n            facts_text = sections[''facts'']\n            if isinstance(facts_text, dict):\n                facts_content = facts_text.get(''text'', facts_text.get(''content'', ''''))\n            else:\n                facts_content = str(facts_text)\n            \n            print(f''\\nFacts section (first 500 chars):'')\n            print(facts_content[:500])\n        \n        # Also check conclusion which might have role info\n        if ''conclusion'' in sections:\n            conclusion = sections[''conclusion'']\n            if isinstance(conclusion, dict):\n                conclusion_content = conclusion.get(''text'', conclusion.get(''content'', ''''))\n            else:\n                conclusion_content = str(conclusion)\n                \n            print(f''\\nConclusion section (first 300 chars):'')\n            print(conclusion_content[:300])\n    else:\n        print(''Case 12 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''ENHANCED_SCENARIO_GENERATION''] = ''true''\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.scenario_pipeline.scenario_generation_phase_a import DirectScenarioPipelineService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    # Test with case 12 that user mentioned\n    case = Document.query.get(12)\n    if case:\n        print(f''üß™ TESTING: Enhanced role extraction for Case {case.id}'')\n        print(f''Title: {case.title}'')\n        \n        try:\n            pipeline = DirectScenarioPipelineService()\n            result = pipeline.generate(case, overwrite=True)\n            \n            if ''scenario_id'' in result:\n                scenario_id = result[''scenario_id'']\n                print(f''\\nüéÆ Enhanced scenario created: {scenario_id}'')\n                \n                # Check the created models for improved role extraction\n                from app.models.scenario import Scenario\n                scenario = Scenario.query.get(scenario_id)\n                if scenario:\n                    print(f''\\nüë• PARTICIPANTS WITH ENHANCED ROLES:'')\n                    for char in scenario.characters:\n                        print(f''  ‚Ä¢ {char.name} ‚Üí {char.role}'')\n                    \n                    print(f''\\nüéâ SUCCESS! Enhanced role extraction working!'')\n                    print(f''üîó View at: http://localhost:3333/scenarios/{scenario_id}'')\n                else:\n                    print(f''‚ùå Scenario {scenario_id} not found in database'')\n            else:\n                print(f''‚ùå No scenario ID found in result'')\n                    \n        except Exception as e:\n            print(f''‚ùå Error: {e}'')\n            import traceback\n            traceback.print_exc()\n    else:\n        print(''‚ùå Case 12 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.scenario import Scenario\n\napp = create_app(''config'')\n\nwith app.app_context():\n    # Check the latest scenario (likely 20 or 21)\n    scenarios = Scenario.query.order_by(Scenario.id.desc()).limit(3).all()\n    for scenario in scenarios:\n        print(f''üéÆ Scenario {scenario.id}: {scenario.name}'')\n        if scenario.characters:\n            print(f''  Participants:'')\n            for char in scenario.characters:\n                print(f''    - {char.name}: {char.role}'')\n        else:\n            print(''  No participants found'')\n        print()\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''ENHANCED_SCENARIO_GENERATION''] = ''true''\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.scenario_pipeline.scenario_generation_phase_a import DirectScenarioPipelineService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    case = Document.query.get(12)\n    if case:\n        print(f''üöÄ Testing refined role extraction for Case {case.id}'')\n        \n        try:\n            pipeline = DirectScenarioPipelineService()\n            result = pipeline.generate(case, overwrite=True)\n            \n            if ''scenario_id'' in result:\n                scenario_id = result[''scenario_id'']\n                print(f''‚úÖ Enhanced scenario created: {scenario_id}'')\n                \n                # Check the participant roles\n                from app.models.scenario import Scenario\n                scenario = Scenario.query.get(scenario_id)\n                if scenario and scenario.characters:\n                    print(f''\\nüë• Participants with refined roles:'')\n                    for char in scenario.characters:\n                        print(f''  - {char.name}: {char.role}'')\n                        \n                    print(f''\\nüéâ Scenario ready at: http://localhost:3333/scenarios/{scenario_id}'')\n                else:\n                    print(''‚ùå No participants found'')\n            else:\n                print(''‚ùå No scenario created'')\n                    \n        except Exception as e:\n            print(f''‚ùå Error: {e}'')\n    else:\n        print(''‚ùå Case 12 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''ENHANCED_SCENARIO_GENERATION''] = ''true''\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.scenario_pipeline.scenario_generation_phase_a import DirectScenarioPipelineService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    case = Document.query.get(12)\n    if case:\n        print(f''üîß Final test of refined role extraction for Case {case.id}'')\n        \n        try:\n            pipeline = DirectScenarioPipelineService()\n            result = pipeline.generate(case, overwrite=True)\n            \n            if ''scenario_id'' in result:\n                scenario_id = result[''scenario_id'']\n                \n                # Check the participant roles\n                from app.models.scenario import Scenario\n                scenario = Scenario.query.get(scenario_id)\n                if scenario and scenario.characters:\n                    print(f''\\n‚úÖ Final participant roles (Scenario {scenario_id}):'')\n                    for char in scenario.characters:\n                        print(f''  - {char.name}: {char.role}'')\n                        \n                    # Check if the roles are now correct\n                    roles_correct = True\n                    for char in scenario.characters:\n                        if ''Local engineering firms'' in char.name and ''Engineering Firms (Local)'' not in char.role:\n                            roles_correct = False\n                            print(f''  ‚ö†Ô∏è  Still needs fixing: {char.name} -> {char.role}'')\n                    \n                    if roles_correct:\n                        print(f''\\nüéâ SUCCESS: All roles extracted correctly!'')\n                        print(f''üîó View at: http://localhost:3333/scenarios/{scenario_id}'')\n                    else:\n                        print(f''\\n‚ö†Ô∏è  Some roles still need refinement'')\n                else:\n                    print(''‚ùå No participants found'')\n            else:\n                print(''‚ùå No scenario created'')\n                    \n        except Exception as e:\n            print(f''‚ùå Error: {e}'')\n    else:\n        print(''‚ùå Case 12 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''ENHANCED_SCENARIO_GENERATION''] = ''true''\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.scenario_pipeline.scenario_generation_phase_a import DirectScenarioPipelineService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    case = Document.query.get(12)\n    if case:\n        print(f''üß™ Testing LLM-based role extraction for Case {case.id}'')\n        print(f''Title: {case.title}'')\n        \n        try:\n            pipeline = DirectScenarioPipelineService()\n            result = pipeline.generate(case, overwrite=True)\n            \n            if ''scenario_id'' in result:\n                scenario_id = result[''scenario_id'']\n                print(f''\\n‚úÖ Enhanced scenario created: {scenario_id}'')\n                \n                # Check the participant roles\n                from app.models.scenario import Scenario\n                scenario = Scenario.query.get(scenario_id)\n                if scenario and scenario.characters:\n                    print(f''\\nüë• LLM-extracted participant roles:'')\n                    for char in scenario.characters:\n                        print(f''  - {char.name}: {char.role}'')\n                        \n                    print(f''\\nüéâ SUCCESS! LLM-based role extraction complete!'')\n                    print(f''üîó View at: http://localhost:3333/scenarios/{scenario_id}'')\n                    print(f''üìÑ Original case: http://localhost:3333/cases/12'')\n                else:\n                    print(''‚ùå No participants found'')\n            else:\n                print(''‚ùå No scenario created'')\n                    \n        except Exception as e:\n            print(f''‚ùå Error: {e}'')\n            import traceback\n            traceback.print_exc()\n    else:\n        print(''‚ùå Case 12 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''ENHANCED_SCENARIO_GENERATION''] = ''true''\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.scenario_pipeline.scenario_generation_phase_a import DirectScenarioPipelineService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    case = Document.query.get(12)\n    if case:\n        print(f''üéØ Testing fixed LLM-based role extraction for Case {case.id}'')\n        \n        try:\n            pipeline = DirectScenarioPipelineService()\n            result = pipeline.generate(case, overwrite=True)\n            \n            if ''scenario_id'' in result:\n                scenario_id = result[''scenario_id'']\n                print(f''‚úÖ Enhanced scenario created: {scenario_id}'')\n                \n                # Check the participant roles\n                from app.models.scenario import Scenario\n                scenario = Scenario.query.get(scenario_id)\n                if scenario and scenario.characters:\n                    print(f''\\nüéâ LLM-extracted participant roles (Scenario {scenario_id}):'')\n                    for char in scenario.characters:\n                        print(f''  ‚úÖ {char.name}: {char.role}'')\n                        \n                    print(f''\\nüöÄ SUCCESS! Intelligent role extraction complete!'')\n                    print(f''üîó Perfect scenario: http://localhost:3333/scenarios/{scenario_id}'')\n                    print(f''üìÑ Source case: http://localhost:3333/cases/12'')\n                    \n                    # Show improvement\n                    print(f''\\nüí° IMPROVEMENT: Roles extracted directly by LLM from case text!'')\n                    print(f''   - No more brittle pattern matching'')\n                    print(f''   - Scales to any case with any participants'')\n                    print(f''   - Intelligent contextual role understanding'')\n                    \n                else:\n                    print(''‚ùå No participants found'')\n            else:\n                print(''‚ùå No scenario created'')\n                    \n        except Exception as e:\n            print(f''‚ùå Error: {e}'')\n            import traceback\n            traceback.print_exc()\n    else:\n        print(''‚ùå Case 12 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.world import World\nfrom app.models.scenario import Scenario\n\napp = create_app(''config'')\n\nwith app.app_context():\n    # Check scenario 24 and its world\n    scenario = Scenario.query.get(24)\n    if scenario:\n        print(f''Scenario 24: {scenario.name}'')\n        print(f''World ID: {scenario.world_id}'')\n        \n        world = World.query.get(scenario.world_id)\n        if world:\n            print(f''World name: {world.name}'')\n            print(f''World ontology_id: {world.ontology_id}'')\n            print(f''World ontology_source: {world.ontology_source}'')\n        else:\n            print(''World not found'')\n    else:\n        print(''Scenario 24 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.world import World\nfrom app.models.scenario import Scenario  \nfrom app.services.ontology_entity_service import OntologyEntityService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    # Get scenario 24 (which user mentioned)\n    scenario = Scenario.query.get(24)\n    if scenario:\n        print(f''Scenario: {scenario.name}'')\n        print(f''World ID: {scenario.world_id}'')\n        \n        world = World.query.get(scenario.world_id)\n        if world:\n            print(f''World: {world.name}'')\n            print(f''Ontology ID: {world.ontology_id}'')\n            print(f''Ontology source: {world.ontology_source}'')\n            \n            # Test the OntologyEntityService\n            service = OntologyEntityService.get_instance()\n            entities = service.get_entities_for_world(world)\n            \n            print(f''\\nEntity categories found: {list(entities.get(\"\"entities\"\", {}).keys())}'')\n            \n            if ''entities'' in entities and ''role'' in entities[''entities'']:\n                roles = entities[''entities''][''role'']\n                print(f''\\nFound {len(roles)} roles:'')\n                for i, role in enumerate(roles[:5]):  # Show first 5\n                    print(f''  {i+1}. {role.get(\"\"label\"\", \"\"No label\"\")} - {role.get(\"\"id\"\", \"\"No ID\"\")}'')\n                    if role.get(''description''):\n                        print(f''      Description: {role[\"\"description\"\"][:100]}...'')\n            else:\n                print(''\\n‚ùå No roles found in ontology'')\n        else:\n            print(''‚ùå World not found'')\n    else:\n        print(''‚ùå Scenario 24 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.scenario import Scenario\nfrom app.models.character import Character\n\napp = create_app(''config'')\n\nwith app.app_context():\n    # Get a character from scenario 24\n    scenario = Scenario.query.get(24)\n    if scenario and scenario.characters:\n        character = scenario.characters[0]  # Get first character\n        print(f''‚úÖ Testing edit character route for:'')\n        print(f''  Scenario: {scenario.name} (ID: {scenario.id})'')\n        print(f''  Character: {character.name} (ID: {character.id})'')\n        print(f''  Character role: {character.role}'')\n        print()\n        print(f''üîó Edit URL: http://localhost:3333/scenarios/{scenario.id}/characters/{character.id}/edit'')\n    else:\n        print(''‚ùå No characters found in scenario 24'')\n\")",
      "WebFetch(domain:docs.anthropic.com)",
      "Bash(/home/chris/onto/proethica/venv/bin/python:*)",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.models.guideline import Guideline\n\napp = create_app(''config'')\nwith app.app_context():\n    # Check document 36\n    doc = Document.query.get(36)\n    if doc:\n        print(f''Document 36: {doc.title}'')\n        print(f''  Type: {doc.document_type}'')\n        print(f''  World ID: {doc.world_id}'')\n        if doc.doc_metadata and ''guideline_id'' in doc.doc_metadata:\n            print(f''  Links to Guideline ID: {doc.doc_metadata[\"\"guideline_id\"\"]}'')\n    else:\n        print(''Document 36 not found'')\n    \n    print(''\\n--- Guidelines Table ---'')\n    guidelines = Guideline.query.all()\n    for g in guidelines:\n        print(f''Guideline {g.id}: {g.title} (World {g.world_id})'')\n    \n    print(''\\n--- Documents with type=guideline ---'')\n    guideline_docs = Document.query.filter_by(document_type=''guideline'').all()\n    for doc in guideline_docs:\n        guideline_id = doc.doc_metadata.get(''guideline_id'', ''N/A'') if doc.doc_metadata else ''N/A''\n        print(f''Document {doc.id}: {doc.title} -> Guideline {guideline_id}'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\n\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.guideline_analysis_service_v2 import GuidelineAnalysisServiceV2\n\napp = create_app(''config'')\n\nwith app.app_context():\n    doc = Document.query.get(36)\n    if doc:\n        service = GuidelineAnalysisServiceV2()\n        result = service.extract_concepts_v2(content=doc.content, guideline_id=36, world_id=1)\n        \n        concepts = result.get(''concepts'', [])\n        \n        print(''Sample concept data structures:'')\n        for i, concept in enumerate(concepts[:3]):\n            print(f''\\nConcept {i+1}: {concept.get(\"\"label\"\")}'')\n            print(f''  Keys: {list(concept.keys())}'')\n            print(f''  ontology_match: {concept.get(\"\"ontology_match\"\")}'')\n            print(f''  is_new: {concept.get(\"\"is_new\"\")}'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nimport os\nos.environ[''SQLALCHEMY_DATABASE_URI''] = os.environ[''DATABASE_URL'']\nfrom app import create_app\nfrom app.models.document import Document\nfrom app import db\n\napp = create_app(''config'')\n\nwith app.app_context():\n    # Clear cache one more time for testing unified service\n    doc = Document.query.get(36)\n    if doc:\n        doc.doc_metadata = {}\n        from sqlalchemy.orm.attributes import flag_modified\n        flag_modified(doc, ''doc_metadata'')\n        db.session.commit()\n        print(''‚úÖ Cache cleared for unified service test'')\n    else:\n        print(''Document 36 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.guideline_analysis_service import GuidelineAnalysisService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    # Test with guideline 36\n    doc = Document.query.get(36)\n    if doc:\n        print(f''‚úÖ Testing unified service with document {doc.id}: {doc.title}'')\n        \n        service = GuidelineAnalysisService()\n        result = service.extract_concepts(\n            content=doc.content,\n            guideline_id=36,\n            world_id=1\n        )\n        \n        concepts = result.get(''concepts'', [])\n        print(f''üìä Extracted {len(concepts)} concepts'')\n        \n        existing_concepts = [c for c in concepts if not c.get(''is_new'', True)]\n        new_concepts = [c for c in concepts if c.get(''is_new'', True)]\n        \n        print(f''üéØ Existing: {len(existing_concepts)}, New: {len(new_concepts)}'')\n        \n        if existing_concepts:\n            print(''‚úÖ Sample existing concepts:'')\n            for c in existing_concepts[:3]:\n                print(f''  - {c.get(\"\"label\"\", \"\"Unknown\"\")} (type: {c.get(\"\"type\"\", \"\"unknown\"\")})'')\n                \n        if new_concepts:\n            print(''üÜï Sample new concepts:'')\n            for c in new_concepts[:3]:\n                print(f''  - {c.get(\"\"label\"\", \"\"Unknown\"\")} (type: {c.get(\"\"type\"\", \"\"unknown\"\")})'')\n                \n        print(f''üéâ SUCCESS: Unified service working correctly!'')\n    else:\n        print(''‚ùå Document 36 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.guideline_analysis_service import GuidelineAnalysisService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    # Test with guideline 36\n    doc = Document.query.get(36)\n    if doc:\n        print(f''‚úÖ Testing unified service with document {doc.id}: {doc.title}'')\n        \n        service = GuidelineAnalysisService()\n        result = service.extract_concepts(\n            content=doc.content,\n            guideline_id=36,\n            world_id=1\n        )\n        \n        concepts = result.get(''concepts'', [])\n        print(f''üìä Extracted {len(concepts)} concepts'')\n        \n        existing_concepts = [c for c in concepts if not c.get(''is_new'', True)]\n        new_concepts = [c for c in concepts if c.get(''is_new'', True)]\n        \n        print(f''üéØ Existing: {len(existing_concepts)}, New: {len(new_concepts)}'')\n        \n        if existing_concepts:\n            print(''‚úÖ Sample existing concepts:'')\n            for c in existing_concepts[:3]:\n                print(f''  - {c.get(\"\"label\"\", \"\"Unknown\"\")} (type: {c.get(\"\"type\"\", \"\"unknown\"\")})'')\n                \n        if new_concepts:\n            print(''üÜï Sample new concepts:'')\n            for c in new_concepts[:3]:\n                print(f''  - {c.get(\"\"label\"\", \"\"Unknown\"\")} (type: {c.get(\"\"type\"\", \"\"unknown\"\")})'')\n                \n        print(f''üéâ SUCCESS: Unified service working correctly!'')\n    else:\n        print(''‚ùå Document 36 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.guideline_analysis_service import GuidelineAnalysisService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    # Test with guideline 36  \n    doc = Document.query.get(36)\n    if doc:\n        print(f''‚úÖ Testing final unified service with document {doc.id}: {doc.title}'')\n        \n        service = GuidelineAnalysisService()\n        result = service.extract_concepts(\n            content=doc.content,\n            guideline_id=36,\n            world_id=1\n        )\n        \n        concepts = result.get(''concepts'', [])\n        print(f''üìä Extracted {len(concepts)} concepts'')\n        \n        existing_concepts = [c for c in concepts if not c.get(''is_new'', True)]\n        new_concepts = [c for c in concepts if c.get(''is_new'', True)]\n        \n        print(f''üéØ Existing: {len(existing_concepts)}, New: {len(new_concepts)}'')\n        \n        if existing_concepts:\n            print(''‚úÖ Sample existing concepts:'')\n            for c in existing_concepts[:3]:\n                print(f''  - {c.get(\"\"label\"\", \"\"Unknown\"\")} (type: {c.get(\"\"type\"\", \"\"unknown\"\")})'')\n                \n        if new_concepts:\n            print(''üÜï Sample new concepts:'')\n            for c in new_concepts[:3]:\n                print(f''  - {c.get(\"\"label\"\", \"\"Unknown\"\")} (type: {c.get(\"\"type\"\", \"\"unknown\"\")})'')\n        \n        print(f'''')\n        print(f''üéâ FINAL SUCCESS!'')\n        print(f''‚úÖ V1/V2 services unified - no more versioning confusion'')\n        print(f''‚úÖ Caching removed - always fresh extraction for easy testing'')\n        print(f''‚úÖ LLM API fixed - proper Anthropic messages.create() call'')\n        print(f''‚úÖ Category error fixed - handles both type and category fields'')\n        print(f''‚úÖ Ready for web testing!'')\n    else:\n        print(''‚ùå Document 36 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nfrom app.routes.worlds_direct_concepts import direct_concept_extraction\nprint(''‚úÖ Import successful - no more v2 service references'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.guideline_analysis_service import GuidelineAnalysisService\n\napp = create_app(''config'')\n\nwith app.app_context():\n    # Test with guideline 36\n    doc = Document.query.get(36)\n    if doc:\n        print(f''‚úÖ Testing corrected LLM client with document {doc.id}: {doc.title}'')\n        \n        service = GuidelineAnalysisService()\n        result = service.extract_concepts(\n            content=doc.content,\n            guideline_id=36,\n            world_id=1\n        )\n        \n        concepts = result.get(''concepts'', [])\n        print(f''üìä Extracted {len(concepts)} concepts'')\n        \n        if len(concepts) > 0:\n            print(''‚úÖ Sample concepts:'')\n            for c in concepts[:3]:\n                print(f''  - {c.get(\"\"label\"\", \"\"Unknown\"\")} (type: {c.get(\"\"type\"\", \"\"unknown\"\")})'')\n            print(f''üéâ SUCCESS: LLM client issue resolved!'')\n        else:\n            print(''‚ùå Still no concepts extracted'')\n    else:\n        print(''‚ùå Document 36 not found'')\n\")",
      "Bash(git fetch:*)",
      "Bash(git checkout:*)",
      "Bash(git merge:*)",
      "Bash(DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python scripts/run_temp_concepts_migration.py)",
      "Bash(SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app\nfrom app.models.temporary_concept import TemporaryConcept\n\nclass TestConfig:\n    SQLALCHEMY_DATABASE_URI = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n    TESTING = True\n\napp = create_app(TestConfig)\nwith app.app_context():\n    concepts = TemporaryConcept.query.all()\n    print(f''Total temporary concepts: {len(concepts)}'')\n    \n    # Show recent sessions\n    sessions = {}\n    for c in concepts:\n        if c.session_id not in sessions:\n            sessions[c.session_id] = {''count'': 0, ''status'': c.status, ''doc_id'': c.document_id}\n        sessions[c.session_id][''count''] += 1\n    \n    print(''Recent sessions:'')\n    for session_id, info in sessions.items():\n        print(f''  {session_id}: {info[\"\"count\"\"]} concepts (status: {info[\"\"status\"\"]}) for doc {info[\"\"doc_id\"\"]}'')\n\")",
      "Bash(ANTHROPIC_API_KEY=test SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app\nfrom app.models.temporary_concept import TemporaryConcept\n\nclass TestConfig:\n    SQLALCHEMY_DATABASE_URI = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n    TESTING = True\n    SECRET_KEY = ''test-key''\n\napp = create_app(TestConfig)\nwith app.app_context():\n    concepts = TemporaryConcept.query.all()\n    print(f''Total temporary concepts: {len(concepts)}'')\n    \n    # Show recent sessions\n    sessions = {}\n    for c in concepts:\n        if c.session_id not in sessions:\n            sessions[c.session_id] = {''count'': 0, ''status'': c.status, ''doc_id'': c.document_id}\n        sessions[c.session_id][''count''] += 1\n    \n    print(''Recent sessions:'')\n    for session_id, info in sessions.items():\n        print(f''  {session_id}: {info[\"\"count\"\"]} concepts (status: {info[\"\"status\"\"]}) for doc {info[\"\"doc_id\"\"]}'')\n\")",
      "Bash(ANTHROPIC_API_KEY=test SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app\nfrom app.models.temporary_concept import TemporaryConcept\n\nclass TestConfig:\n    SQLALCHEMY_DATABASE_URI = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n    TESTING = True\n    SECRET_KEY = ''test-key''\n\napp = create_app(TestConfig)\nwith app.app_context():\n    concepts = TemporaryConcept.query.all()\n    print(f''Total temporary concepts: {len(concepts)}'')\n    \n    # Show recent sessions\n    sessions = {}\n    for c in concepts:\n        if c.session_id not in sessions:\n            sessions[c.session_id] = {''count'': 0, ''status'': c.status, ''doc_id'': c.document_id}\n        sessions[c.session_id][''count''] += 1\n    \n    print(''Recent sessions:'')\n    for session_id, info in sessions.items():\n        print(f''  {session_id}: {info[\"\"count\"\"]} concepts (status: {info[\"\"status\"\"]}) for doc {info[\"\"doc_id\"\"]}'')\n\")",
      "Bash(ANTHROPIC_API_KEY=test SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app\nfrom app.routes.dashboard import get_system_statistics\n\nclass TestConfig:\n    SQLALCHEMY_DATABASE_URI = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n    TESTING = True\n    SECRET_KEY = ''test-key''\n\napp = create_app(TestConfig)\nwith app.app_context():\n    stats = get_system_statistics()\n    print(''Dashboard Statistics:'')\n    print(f''  Total guidelines: {stats[\"\"analysis\"\"][\"\"total_guidelines\"\"]}'')\n    print(f''  Analyzed guidelines: {stats[\"\"analysis\"\"][\"\"analyzed_guidelines\"\"]}'')\n    print(f''  Pending concepts: {stats[\"\"analysis\"\"][\"\"pending_concepts\"\"]}'')\n    print(f''  Pending sessions: {stats[\"\"analysis\"\"][\"\"pending_sessions\"\"]}'')\n    \n    print()\n    if stats[''analysis''][''pending_concepts''] > 0:\n        print(''‚úÖ Dashboard will show pending concepts indicator'')\n        print(f''Button text: \"\"{stats[\"\"analysis\"\"][\"\"pending_concepts\"\"]} concepts in {stats[\"\"analysis\"\"][\"\"pending_sessions\"\"]} sessions\"\"'')\n    else:\n        print(''‚ùå No pending concepts - indicator will not show'')\n\")",
      "Bash(ANTHROPIC_API_KEY=test SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.temporary_concept_service import TemporaryConceptService\n\nclass TestConfig:\n    SQLALCHEMY_DATABASE_URI = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n    TESTING = True\n    SECRET_KEY = ''test-key''\n\napp = create_app(TestConfig)\nwith app.app_context():\n    # Check guideline document 36 (which we know has pending concepts)\n    document = Document.query.get(36)\n    if document:\n        print(f''Guideline: {document.title}'')\n        print(f''Type: {document.document_type}'')\n        print(f''World ID: {document.world_id}'')\n        \n        # Check for pending extractions\n        session_id = TemporaryConceptService.get_latest_session_for_document(36, 1)\n        if session_id:\n            temp_concepts = TemporaryConceptService.get_session_concepts(session_id)\n            print(f''\\n‚úÖ Pending extraction found:'')\n            print(f''  Session ID: {session_id}'')\n            print(f''  Concept count: {len(temp_concepts)}'')\n            print(f''  Status: {temp_concepts[0].status if temp_concepts else \"\"unknown\"\"}'')\n            if temp_concepts:\n                print(f''  Extraction date: {temp_concepts[0].extraction_timestamp}'')\n                \n            print(f''\\nGuideline page will show:'')\n            print(f''  - Pending extraction alert'')\n            print(f''  - \"\"Load Pending Concepts ({len(temp_concepts)})\"\" button instead of \"\"Analyze Concepts\"\"'')\n        else:\n            print(''‚ùå No pending extractions found'')\n    else:\n        print(''‚ùå Document 36 not found'')\n\")",
      "Bash(ANTHROPIC_API_KEY=test SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app\nfrom app.services.temporary_concept_service import TemporaryConceptService\n\nclass TestConfig:\n    SQLALCHEMY_DATABASE_URI = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n    TESTING = True\n    SECRET_KEY = ''test-key''\n\napp = create_app(TestConfig)\nwith app.app_context():\n    # Test the route that retrieves concepts from temporary storage\n    session_id = ''doc36_world1_20250821095044_70a4c82b''\n    temp_concepts = TemporaryConceptService.get_session_concepts(session_id, status=''pending'')\n    \n    if temp_concepts:\n        concepts_list = [tc.concept_data for tc in temp_concepts]\n        print(f''‚úÖ Retrieved {len(concepts_list)} concepts from temporary storage'')\n        print(f''Session ID: {session_id}'')\n        print(f''Status: {temp_concepts[0].status}'')\n        \n        # Show sample concept data\n        if concepts_list:\n            sample_concept = concepts_list[0]\n            print(f''\\nSample concept:'')\n            print(f''  Label: {sample_concept.get(\"\"label\"\", \"\"Unknown\"\")}'')\n            print(f''  Type: {sample_concept.get(\"\"type\"\", \"\"unknown\"\")}'')\n            print(f''  Is new: {sample_concept.get(\"\"is_new\"\", True)}'')\n            \n        print(f''\\n‚úÖ The review_concepts_from_temp route will work correctly'')\n        print(f''URL: /worlds/1/guidelines/36/review_concepts_from_temp'')\n    else:\n        print(''‚ùå No concepts retrieved from temporary storage'')\n\")",
      "Bash(ANTHROPIC_API_KEY=test SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app\nfrom app.services.temporary_concept_service import TemporaryConceptService\n\nclass TestConfig:\n    SQLALCHEMY_DATABASE_URI = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n    TESTING = True\n    SECRET_KEY = ''test-key''\n\napp = create_app(TestConfig)\nwith app.app_context():\n    # Get the latest session for document 36\n    session_id = TemporaryConceptService.get_latest_session_for_document(36, 1)\n    if session_id:\n        temp_concepts = TemporaryConceptService.get_session_concepts(session_id)\n        \n        print(f''Session: {session_id}'')\n        print(f''Total concepts: {len(temp_concepts)}'')\n        \n        # Check the structure of a few concepts\n        for i, tc in enumerate(temp_concepts[:3]):\n            concept_data = tc.concept_data\n            print(f''\\nConcept {i+1}:'')\n            print(f''  Label: {concept_data.get(\"\"label\"\", \"\"Unknown\"\")}'')\n            print(f''  Type: {concept_data.get(\"\"type\"\", \"\"unknown\"\")}'')\n            print(f''  Keys: {list(concept_data.keys())}'')\n            \n            # Check for relationship/predicate information\n            if ''relationships'' in concept_data:\n                print(f''  Relationships: {len(concept_data[\"\"relationships\"\"])}'')\n            if ''predicates'' in concept_data:\n                print(f''  Predicates: {concept_data[\"\"predicates\"\"]}'')\n            if ''suggested_predicates'' in concept_data:\n                print(f''  Suggested predicates: {concept_data[\"\"suggested_predicates\"\"]}'')\n    else:\n        print(''No session found'')\n\")",
      "Bash(ANTHROPIC_API_KEY=test SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.guideline_analysis_service import GuidelineAnalysisService\n\nclass TestConfig:\n    SQLALCHEMY_DATABASE_URI = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n    TESTING = True\n    SECRET_KEY = ''test-key''\n\napp = create_app(TestConfig)\nwith app.app_context():\n    # Test extracting concepts with relationships\n    doc = Document.query.get(36)\n    if doc:\n        print(f''Testing concept extraction with relationships for: {doc.title}'')\n        \n        service = GuidelineAnalysisService()\n        # Extract without temp storage to see full result\n        result = service.extract_concepts(\n            content=doc.content, \n            guideline_id=36, \n            world_id=1,\n            use_temp_storage=False\n        )\n        \n        if ''relationships'' in result:\n            relationships = result[''relationships'']\n            print(f''\\n‚úÖ Found {len(relationships)} relationships:'')\n            \n            for i, rel in enumerate(relationships[:5]):  # Show first 5\n                print(f''  {i+1}. Subject: {rel.get(\"\"subject\"\", \"\"Unknown\"\")}'')\n                print(f''      Predicate: {rel.get(\"\"predicate\"\", \"\"Unknown\"\")}'')\n                print(f''      Object: {rel.get(\"\"object\"\", \"\"Unknown\"\")}'')\n                print(f''      Confidence: {rel.get(\"\"confidence\"\", 0)}'')\n                print(f''      Explanation: {rel.get(\"\"explanation\"\", \"\"No explanation\"\")}'')\n                print()\n                \n            print(f''Total concepts: {len(result.get(\"\"concepts\"\", []))}'')\n            print(f''Total relationships: {len(relationships)}'')\n        else:\n            print(''‚ùå No relationships found in extraction result'')\n            print(f''Result keys: {list(result.keys())}'')\n    else:\n        print(''Document 36 not found'')\n\")",
      "Bash(ANTHROPIC_API_KEY=test SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app\nfrom app.services.guideline_analysis_service import GuidelineAnalysisService\n\nclass TestConfig:\n    SQLALCHEMY_DATABASE_URI = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n    TESTING = True\n    SECRET_KEY = ''test-key''\n\napp = create_app(TestConfig)\nwith app.app_context():\n    # Test the _add_predicates_to_concepts method with mock data\n    service = GuidelineAnalysisService()\n    \n    # Mock concepts\n    concepts = [\n        {\n            ''label'': ''Engineer Role'',\n            ''type'': ''role'',\n            ''ontology_match'': {''uri'': ''http://example.org/Engineer''},\n            ''is_new'': False\n        },\n        {\n            ''label'': ''Public Safety Principle'',\n            ''type'': ''principle'', \n            ''ontology_match'': {''uri'': ''http://example.org/PublicSafety''},\n            ''is_new'': False\n        }\n    ]\n    \n    # Mock relationships\n    relationships = [\n        {\n            ''subject'': ''http://example.org/Engineer'',\n            ''predicate'': ''http://proethica.org/ontology/intermediate#adheresToPrinciple'',\n            ''object'': ''http://example.org/PublicSafety'',\n            ''confidence'': 0.85,\n            ''explanation'': ''Engineers must adhere to public safety principles''\n        }\n    ]\n    \n    # Test the enhancement\n    enhanced = service._add_predicates_to_concepts(concepts, relationships)\n    \n    print(''‚úÖ Enhancement test results:'')\n    for concept in enhanced:\n        print(f''\\nConcept: {concept[\"\"label\"\"]}'')\n        print(f''  As subject: {len(concept[\"\"suggested_predicates\"\"][\"\"as_subject\"\"])} predicates'')\n        print(f''  As object: {len(concept[\"\"suggested_predicates\"\"][\"\"as_object\"\"])} predicates'')\n        \n        # Show details\n        for pred in concept[''suggested_predicates''][''as_subject'']:\n            print(f''    ‚Üí {pred[\"\"predicate_type\"\"]} {pred[\"\"target_label\"\"]} (confidence: {pred[\"\"confidence\"\"]})'')\n        \n        for pred in concept[''suggested_predicates''][''as_object'']:\n            print(f''    ‚Üê {pred[\"\"source_label\"\"]} {pred[\"\"predicate_type\"\"]} (confidence: {pred[\"\"confidence\"\"]})'')\n\")",
      "Bash(ANTHROPIC_API_KEY=test SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app\nfrom app.services.guideline_analysis_service import GuidelineAnalysisService\nfrom app.services.temporary_concept_service import TemporaryConceptService\n\nclass TestConfig:\n    SQLALCHEMY_DATABASE_URI = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n    TESTING = True\n    SECRET_KEY = ''test-key''\n\napp = create_app(TestConfig)\nwith app.app_context():\n    print(''üß™ Testing complete predicate suggestion pipeline'')\n    \n    # Create test service\n    service = GuidelineAnalysisService()\n    \n    # Mock extracted concepts (simulating successful LLM extraction)\n    mock_concepts = [\n        {\n            ''label'': ''Engineer Role'',\n            ''type'': ''role'',\n            ''description'': ''Professional engineering role'',\n            ''ontology_match'': {''uri'': ''http://example.org/Engineer''},\n            ''is_new'': False,\n            ''confidence'': 0.9\n        },\n        {\n            ''label'': ''Public Safety Principle'', \n            ''type'': ''principle'',\n            ''description'': ''Principle of protecting public safety'',\n            ''ontology_match'': {''uri'': ''http://example.org/PublicSafety''},\n            ''is_new'': False,\n            ''confidence'': 0.85\n        },\n        {\n            ''label'': ''Professional Competence Obligation'',\n            ''type'': ''obligation'', \n            ''description'': ''Obligation to maintain competence'',\n            ''ontology_match'': {''uri'': ''http://example.org/Competence''},\n            ''is_new'': True,\n            ''confidence'': 0.8\n        }\n    ]\n    \n    # Mock discovered relationships  \n    mock_relationships = [\n        {\n            ''subject'': ''http://example.org/Engineer'',\n            ''predicate'': ''http://proethica.org/ontology/intermediate#adheresToPrinciple'',\n            ''object'': ''http://example.org/PublicSafety'',\n            ''confidence'': 0.85,\n            ''explanation'': ''Engineers must adhere to public safety principles''\n        },\n        {\n            ''subject'': ''http://example.org/Engineer'',\n            ''predicate'': ''http://proethica.org/ontology/intermediate#hasObligation'', \n            ''object'': ''http://example.org/Competence'',\n            ''confidence'': 0.8,\n            ''explanation'': ''Engineers have obligation to maintain competence''\n        }\n    ]\n    \n    # Test the predicate enhancement\n    enhanced_concepts = service._add_predicates_to_concepts(mock_concepts, mock_relationships)\n    \n    print(f''‚úÖ Enhanced {len(enhanced_concepts)} concepts with predicates'')\n    \n    # Store in temporary storage to test full pipeline\n    try:\n        from app.services.temporary_concept_service import TemporaryConceptService\n        session_id = TemporaryConceptService.store_concepts(\n            concepts=enhanced_concepts,\n            document_id=36,\n            world_id=1,\n            extraction_method=''test''\n        )\n        print(f''‚úÖ Stored concepts with predicates in session: {session_id}'')\n        \n        # Retrieve and verify predicate data persists\n        retrieved_concepts = TemporaryConceptService.get_session_concepts(session_id)\n        \n        print(f''\\nüîç Retrieved {len(retrieved_concepts)} concepts:'')\n        for i, tc in enumerate(retrieved_concepts):\n            concept = tc.concept_data\n            label = concept.get(''label'', ''Unknown'')\n            predicates = concept.get(''suggested_predicates'', {})\n            \n            as_subject_count = len(predicates.get(''as_subject'', []))\n            as_object_count = len(predicates.get(''as_object'', []))\n            \n            print(f''  {i+1}. {label}: {as_subject_count} as subject, {as_object_count} as object'')\n            \n            # Show predicate details\n            for pred in predicates.get(''as_subject'', []):\n                print(f''    ‚Üí {pred[\"\"predicate_type\"\"]} {pred[\"\"target_label\"\"]} ({pred[\"\"confidence\"\"]:.0%})'')\n            for pred in predicates.get(''as_object'', []):\n                print(f''    ‚Üê {pred[\"\"source_label\"\"]} {pred[\"\"predicate_type\"\"]} ({pred[\"\"confidence\"\"]:.0%})'')\n        \n        print(f''\\nüéâ SUCCESS: Predicate suggestions working end-to-end!'')\n        print(f''üåê Template will display these predicates at: /worlds/1/guidelines/36/review_concepts_from_temp'')\n        \n    except Exception as e:\n        print(f''‚ùå Storage test failed: {e}'')\n        import traceback\n        traceback.print_exc()\n\")",
      "Bash(ANTHROPIC_API_KEY=test SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app\nfrom app.services.temporary_concept_service import TemporaryConceptService\n\nclass TestConfig:\n    SQLALCHEMY_DATABASE_URI = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n    TESTING = True\n    SECRET_KEY = ''test-key''\n\napp = create_app(TestConfig)\nwith app.app_context():\n    print(''üåê Testing web interface access to enhanced concepts'')\n    \n    # Get the latest session (our test session with predicates)\n    session_id = TemporaryConceptService.get_latest_session_for_document(36, 1)\n    print(f''Latest session: {session_id}'')\n    \n    if session_id:\n        # This is what the route would do\n        temp_concepts = TemporaryConceptService.get_session_concepts(session_id, status=''pending'')\n        concepts_list = [tc.concept_data for tc in temp_concepts]\n        \n        print(f''\\nüìã Template would receive {len(concepts_list)} concepts:'')\n        for i, concept in enumerate(concepts_list, 1):\n            print(f''  {i}. {concept[\"\"label\"\"]} ({concept[\"\"type\"\"]})'')\n            \n            # Check template conditions\n            predicates = concept.get(''suggested_predicates'', {})\n            has_predicates = (len(predicates.get(''as_subject'', [])) > 0 or \n                            len(predicates.get(''as_object'', [])) > 0)\n            \n            if has_predicates:\n                print(f''     ‚úÖ Has predicates - template will show suggestions'')\n                print(f''     As subject: {len(predicates.get(\"\"as_subject\"\", []))} predicates'')\n                print(f''     As object: {len(predicates.get(\"\"as_object\"\", []))} predicates'')\n                \n                # Show what would be displayed\n                for pred in predicates.get(''as_subject'', []):\n                    print(f''       ‚Üí Badge: \"\"{pred[\"\"predicate_type\"\"]}\"\" ‚Üí {pred[\"\"target_label\"\"]} ({pred[\"\"confidence\"\"]:.0%})'')\n                for pred in predicates.get(''as_object'', []):\n                    print(f''       ‚Üê {pred[\"\"source_label\"\"]} ‚Üí Badge: \"\"{pred[\"\"predicate_type\"\"]}\"\" ({pred[\"\"confidence\"\"]:.0%})'')\n            else:\n                print(f''     ‚ùå No predicates - template section will be hidden'')\n        \n        print(f''\\nüéØ READY FOR TESTING:'')\n        print(f''   1. Visit: http://localhost:3333/worlds/1/guidelines/36'')  \n        print(f''   2. Click \"\"Load Pending Concepts ({len(concepts_list)})\"\" button'')\n        print(f''   3. See predicate suggestions in concept cards!'')\n    else:\n        print(''‚ùå No session found'')\n\")",
      "Bash(ANTHROPIC_API_KEY=test SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app\nfrom app.services.temporary_concept_service import TemporaryConceptService\n\nclass TestConfig:\n    SQLALCHEMY_DATABASE_URI = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n    TESTING = True\n    SECRET_KEY = ''test-key''\n\napp = create_app(TestConfig)\nwith app.app_context():\n    print(''üß™ Testing predicate suggestions in triple review workflow'')\n    \n    # Get the latest session for document 36 (which has predicate suggestions)\n    session_id = TemporaryConceptService.get_latest_session_for_document(36, 1)\n    if session_id:\n        temp_concepts = TemporaryConceptService.get_session_concepts(session_id)\n        print(f''‚úÖ Session {session_id}: {len(temp_concepts)} concepts'')\n        \n        # Check for predicate suggestions in concepts\n        predicate_count = 0\n        for tc in temp_concepts:\n            concept_data = tc.concept_data\n            predicates = concept_data.get(''suggested_predicates'', {})\n            as_subject = len(predicates.get(''as_subject'', []))\n            as_object = len(predicates.get(''as_object'', []))\n            if as_subject > 0 or as_object > 0:\n                predicate_count += as_subject + as_object\n                print(f''  - {concept_data.get(\"\"label\"\", \"\"Unknown\"\")}: {as_subject + as_object} predicates'')\n        \n        print(f''\\nüìä Total predicate suggestions found: {predicate_count}'')\n        \n        if predicate_count > 0:\n            print(f''‚úÖ SUCCESS: Triple review page will show {predicate_count} predicate suggestions'')\n            print(f''üåê Test URL: /worlds/1/guidelines/36/review_concepts_from_temp'')\n            print(f''   Click \"\"Generate Triples\"\" to see predicate suggestions in triple review'')\n        else:\n            print(''‚ùå No predicate suggestions found in temporary concepts'')\n    else:\n        print(''‚ùå No session found for testing'')\n\")",
      "Bash(ANTHROPIC_API_KEY=test SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app\nfrom app.services.temporary_concept_service import TemporaryConceptService\n\nclass TestConfig:\n    SQLALCHEMY_DATABASE_URI = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n    TESTING = True\n    SECRET_KEY = ''test-key''\n\napp = create_app(TestConfig)\nwith app.app_context():\n    print(''üß™ Testing predicate suggestions in triple review workflow'')\n    \n    # Get the latest session for document 36 (which has predicate suggestions)\n    session_id = TemporaryConceptService.get_latest_session_for_document(36, 1)\n    if session_id:\n        temp_concepts = TemporaryConceptService.get_session_concepts(session_id)\n        print(f''‚úÖ Session {session_id}: {len(temp_concepts)} concepts'')\n        \n        # Check for predicate suggestions in concepts\n        predicate_count = 0\n        sample_predicates = []\n        for tc in temp_concepts:\n            concept_data = tc.concept_data\n            predicates = concept_data.get(''suggested_predicates'', {})\n            as_subject = predicates.get(''as_subject'', [])\n            as_object = predicates.get(''as_object'', [])\n            \n            if len(as_subject) > 0 or len(as_object) > 0:\n                predicate_count += len(as_subject) + len(as_object)\n                concept_label = concept_data.get(''label'', ''Unknown'')\n                print(f''  - {concept_label}: {len(as_subject) + len(as_object)} predicates'')\n                \n                # Store sample predicates for display\n                for pred in as_subject[:2]:  # Show first 2\n                    sample_predicates.append(f''{concept_label} ‚Üí {pred.get(\"\"predicate_type\"\", \"\"unknown\"\")} ‚Üí {pred.get(\"\"target_label\"\", \"\"unknown\"\")}'')\n        \n        print(f''\\nüìä Total predicate suggestions found: {predicate_count}'')\n        \n        if predicate_count > 0:\n            print(f''‚úÖ SUCCESS: Triple review page will show {predicate_count} predicate suggestions'')\n            print(f''\\nüí° Sample predicates that will appear in review:'')\n            for sample in sample_predicates[:3]:\n                print(f''     {sample}'')\n            print(f''\\nüåê Testing workflow:'')\n            print(f''   1. Visit: http://localhost:3333/worlds/1/guidelines/36'')\n            print(f''   2. Click \"\"Load Pending Concepts ({len(temp_concepts)})\"\" button'')\n            print(f''   3. Select concepts and click \"\"Generate Triples\"\"'')\n            print(f''   4. Review the \"\"Predicate Suggestions\"\" tab with {predicate_count} suggestions'')\n        else:\n            print(''‚ùå No predicate suggestions found in temporary concepts'')\n    else:\n        print(''‚ùå No session found for testing'')\n\")",
      "Bash(ANTHROPIC_API_KEY=test SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app\nfrom app.models.document import Document\nfrom app.services.guideline_analysis_service import GuidelineAnalysisService\n\nclass TestConfig:\n    SQLALCHEMY_DATABASE_URI = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n    TESTING = True\n    SECRET_KEY = ''test-key''\n\napp = create_app(TestConfig)\nwith app.app_context():\n    print(''üöÄ Generating concepts with predicate suggestions for document 36'')\n    \n    # Get guideline document 36\n    doc = Document.query.get(36)\n    if doc:\n        print(f''Document: {doc.title}'')\n        \n        try:\n            service = GuidelineAnalysisService()\n            result = service.extract_concepts(\n                content=doc.content,\n                guideline_id=36,\n                world_id=1,\n                use_temp_storage=True\n            )\n            \n            if ''session_id'' in result:\n                session_id = result[''session_id'']\n                concepts_count = len(result.get(''concepts'', []))\n                relationships_count = len(result.get(''relationships'', []))\n                \n                print(f''‚úÖ Generated {concepts_count} concepts with {relationships_count} relationships'')\n                print(f''üìù Session ID: {session_id}'')\n                \n                # Check the enhanced concepts for predicate suggestions\n                from app.services.temporary_concept_service import TemporaryConceptService\n                temp_concepts = TemporaryConceptService.get_session_concepts(session_id)\n                \n                predicate_count = 0\n                enhanced_concepts = 0\n                for tc in temp_concepts:\n                    concept_data = tc.concept_data\n                    predicates = concept_data.get(''suggested_predicates'', {})\n                    as_subject = len(predicates.get(''as_subject'', []))\n                    as_object = len(predicates.get(''as_object'', []))\n                    \n                    if as_subject > 0 or as_object > 0:\n                        enhanced_concepts += 1\n                        predicate_count += as_subject + as_object\n                        concept_label = concept_data.get(''label'', ''Unknown'')\n                        print(f''  ‚Ä¢ {concept_label}: {as_subject + as_object} predicates'')\n                \n                print(f''\\nüéØ RESULTS:'')\n                print(f''   Enhanced concepts: {enhanced_concepts}/{concepts_count}'')\n                print(f''   Total predicate suggestions: {predicate_count}'')\n                \n                if predicate_count > 0:\n                    print(f''\\n‚úÖ SUCCESS: Ready to test triple review with predicate suggestions!'')\n                    print(f''üåê Visit: http://localhost:3333/worlds/1/guidelines/36'')\n                    print(f''   Click \"\"Load Pending Concepts ({concepts_count})\"\"'')\n                    print(f''   Generate triples to see {predicate_count} predicate suggestions'')\n                else:\n                    print(f''‚ö†Ô∏è  No predicate suggestions generated - check relationship extraction'')\n            else:\n                print(f''‚ùå No session created: {result}'')\n                \n        except Exception as e:\n            print(f''‚ùå Error: {e}'')\n            import traceback\n            traceback.print_exc()\n    else:\n        print(''‚ùå Document 36 not found'')\n\")",
      "Bash(ANTHROPIC_API_KEY=test SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app\nfrom app.services.temporary_concept_service import TemporaryConceptService\n\nclass TestConfig:\n    SQLALCHEMY_DATABASE_URI = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n    TESTING = True\n    SECRET_KEY = ''test-key''\n\napp = create_app(TestConfig)\nwith app.app_context():\n    print(''üß™ TESTING: Creating mock concepts with predicate suggestions for document 36'')\n    \n    # Create mock enhanced concepts with predicate suggestions\n    mock_concepts = [\n        {\n            ''label'': ''Engineer Role'',\n            ''type'': ''role'',\n            ''description'': ''Professional engineering role with responsibilities'',\n            ''ontology_match'': {''uri'': ''http://example.org/Engineer''},\n            ''is_new'': False,\n            ''confidence'': 0.9,\n            ''suggested_predicates'': {\n                ''as_subject'': [\n                    {\n                        ''predicate_type'': ''hasObligation'',\n                        ''target_label'': ''Public Safety Obligation'',\n                        ''target_uri'': ''http://example.org/PublicSafetyObligation'',\n                        ''confidence'': 0.85,\n                        ''explanation'': ''Engineers must prioritize public safety''\n                    },\n                    {\n                        ''predicate_type'': ''adheresToPrinciple'', \n                        ''target_label'': ''Professional Competence Principle'',\n                        ''target_uri'': ''http://example.org/CompetencePrinciple'',\n                        ''confidence'': 0.8,\n                        ''explanation'': ''Engineers must maintain professional competence''\n                    }\n                ],\n                ''as_object'': [\n                    {\n                        ''source_label'': ''Engineering Firm'',\n                        ''source_uri'': ''http://example.org/EngineeringFirm'',\n                        ''predicate_type'': ''employs'',\n                        ''confidence'': 0.75,\n                        ''explanation'': ''Engineering firms employ engineers''\n                    }\n                ]\n            }\n        },\n        {\n            ''label'': ''Public Safety Principle'',\n            ''type'': ''principle'',\n            ''description'': ''Principle of protecting public safety'',\n            ''ontology_match'': {''uri'': ''http://example.org/PublicSafety''},\n            ''is_new'': False,\n            ''confidence'': 0.85,\n            ''suggested_predicates'': {\n                ''as_subject'': [],\n                ''as_object'': [\n                    {\n                        ''source_label'': ''Engineer Role'',\n                        ''source_uri'': ''http://example.org/Engineer'',\n                        ''predicate_type'': ''adheresToPrinciple'',\n                        ''confidence'': 0.85,\n                        ''explanation'': ''Engineers must adhere to public safety principles''\n                    }\n                ]\n            }\n        },\n        {\n            ''label'': ''Professional Competence Obligation'',\n            ''type'': ''obligation'',\n            ''description'': ''Obligation to maintain professional competence'',\n            ''ontology_match'': {''uri'': ''http://example.org/Competence''},\n            ''is_new'': True,\n            ''confidence'': 0.8,\n            ''suggested_predicates'': {\n                ''as_subject'': [\n                    {\n                        ''predicate_type'': ''requiresAction'',\n                        ''target_label'': ''Continuing Education Action'',\n                        ''target_uri'': ''http://example.org/ContinuingEducation'',\n                        ''confidence'': 0.7,\n                        ''explanation'': ''Professional competence requires continuing education''\n                    }\n                ],\n                ''as_object'': [\n                    {\n                        ''source_label'': ''Engineer Role'',\n                        ''source_uri'': ''http://example.org/Engineer'', \n                        ''predicate_type'': ''hasObligation'',\n                        ''confidence'': 0.8,\n                        ''explanation'': ''Engineers have obligation to maintain competence''\n                    }\n                ]\n            }\n        }\n    ]\n    \n    # Store mock concepts in temporary storage\n    try:\n        session_id = TemporaryConceptService.store_concepts(\n            concepts=mock_concepts,\n            document_id=36,\n            world_id=1,\n            extraction_method=''mock_test''\n        )\n        print(f''‚úÖ Created mock session: {session_id}'')\n        \n        # Verify predicate suggestions were stored correctly\n        temp_concepts = TemporaryConceptService.get_session_concepts(session_id)\n        \n        predicate_count = 0\n        for tc in temp_concepts:\n            concept_data = tc.concept_data\n            predicates = concept_data.get(''suggested_predicates'', {})\n            as_subject = len(predicates.get(''as_subject'', []))\n            as_object = len(predicates.get(''as_object'', []))\n            \n            if as_subject > 0 or as_object > 0:\n                predicate_count += as_subject + as_object\n                concept_label = concept_data.get(''label'', ''Unknown'')\n                print(f''  ‚Ä¢ {concept_label}: {as_subject} as subject, {as_object} as object predicates'')\n                \n                # Show sample predicates\n                for pred in predicates.get(''as_subject'', []):\n                    print(f''    ‚Üí {pred[\"\"predicate_type\"\"]} ‚Üí {pred[\"\"target_label\"\"]} ({pred[\"\"confidence\"\"]:.0%})'')\n                for pred in predicates.get(''as_object'', []):\n                    print(f''    ‚Üê {pred[\"\"source_label\"\"]} {pred[\"\"predicate_type\"\"]} ({pred[\"\"confidence\"\"]:.0%})'')\n        \n        print(f''\\nüéØ MOCK TEST RESULTS:'')\n        print(f''   Concepts created: {len(mock_concepts)}'')\n        print(f''   Total predicate suggestions: {predicate_count}'')\n        print(f''\\n‚úÖ SUCCESS: Ready to test triple review with predicate suggestions!'')\n        print(f''üåê Test workflow:'')\n        print(f''   1. Visit: http://localhost:3333/worlds/1/guidelines/36'')\n        print(f''   2. Click \"\"Load Pending Concepts ({len(mock_concepts)})\"\" button'')\n        print(f''   3. Select concepts and click \"\"Generate Triples\"\"'')\n        print(f''   4. Check \"\"Predicate Suggestions\"\" tab with {predicate_count} AI suggestions'')\n        \n    except Exception as e:\n        print(f''‚ùå Error creating mock session: {e}'')\n        import traceback\n        traceback.print_exc()\n\")",
      "Bash(ANTHROPIC_API_KEY=test SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app\nfrom app.services.temporary_concept_service import TemporaryConceptService\n\nclass TestConfig:\n    SQLALCHEMY_DATABASE_URI = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n    TESTING = True\n    SECRET_KEY = ''test-key''\n\napp = create_app(TestConfig)\nwith app.app_context():\n    print(''üîß FINAL TEST: Verifying predicate triple extraction functionality'')\n    \n    # Get the latest mock session\n    session_id = TemporaryConceptService.get_latest_session_for_document(36, 1)\n    if session_id:\n        temp_concepts = TemporaryConceptService.get_session_concepts(session_id)\n        concepts_list = [tc.concept_data for tc in temp_concepts]\n        \n        print(f''üìã Testing with {len(concepts_list)} concepts from session: {session_id}'')\n        \n        # Import the _extract_predicate_triples function from worlds.py\n        from app.routes.worlds import _extract_predicate_triples\n        from app.models.world import World\n        \n        world = World.query.get(1)\n        predicate_triples = _extract_predicate_triples(concepts_list, 36, world)\n        \n        print(f''‚úÖ Generated {len(predicate_triples)} predicate suggestion triples:'')\n        \n        for i, triple in enumerate(predicate_triples, 1):\n            print(f''  {i}. {triple[\"\"subject_label\"\"]} ‚Üí {triple[\"\"predicate_label\"\"]} ‚Üí {triple[\"\"object_label\"\"]}'')\n            print(f''     Category: {triple[\"\"category\"\"]}, Confidence: {triple[\"\"confidence\"\"]:.0%}'')\n            if triple.get(''explanation''):\n                print(f''     Explanation: {triple[\"\"explanation\"\"]}'')\n        \n        print(f''\\nüéØ VERIFICATION RESULTS:'')\n        print(f''   ‚úì Predicate extraction function working: {len(predicate_triples) > 0}'')\n        print(f''   ‚úì Triples have correct category: {all(t.get(\"\"category\"\") == \"\"predicate_suggestion\"\" for t in predicate_triples)}'')\n        print(f''   ‚úì Triples have confidence scores: {all(\"\"confidence\"\" in t for t in predicate_triples)}'')\n        print(f''   ‚úì Triples have explanations: {all(\"\"explanation\"\" in t for t in predicate_triples)}'')\n        \n        print(f''\\nüéâ FINAL SUCCESS:'')\n        print(f''   ‚úÖ Template enhancements complete'')\n        print(f''   ‚úÖ Route modifications functional'') \n        print(f''   ‚úÖ Predicate extraction working'')\n        print(f''   ‚úÖ Mock data verification successful'')\n        print(f''\\nüöÄ READY FOR PRODUCTION TESTING!'')\n        print(f''   Navigate to: http://localhost:3333/worlds/1/guidelines/36'')\n        print(f''   Experience: Full predicate suggestions in triple review workflow'')\n        \n    else:\n        print(''‚ùå No session found for final test'')\n\")",
      "Bash(ANTHROPIC_API_KEY=test SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app\nfrom app.services.temporary_concept_service import TemporaryConceptService\n\nclass TestConfig:\n    SQLALCHEMY_DATABASE_URI = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n    TESTING = True\n    SECRET_KEY = ''test-key''\n\napp = create_app(TestConfig)\nwith app.app_context():\n    print(''üß™ TESTING: Complete Direct Save Concepts Workflow'')\n    \n    # Get the latest mock session\n    session_id = TemporaryConceptService.get_latest_session_for_document(36, 1)\n    if session_id:\n        temp_concepts = TemporaryConceptService.get_session_concepts(session_id)\n        concepts_list = [tc.concept_data for tc in temp_concepts]\n        \n        print(f''üìã Testing with {len(concepts_list)} concepts from session: {session_id}'')\n        \n        # Simulate the workflow that happens when user clicks Save Concepts\n        print(f''\\nüîç STEP 1: User views concepts on review page'')\n        print(f''   - Concepts displayed with predicate suggestions'')\n        print(f''   - User selects concepts (simulating all selected)'')\n        selected_indices = list(range(len(concepts_list)))\n        selected_concepts = [concepts_list[i] for i in selected_indices]\n        \n        print(f''\\nüí° STEP 2: Modal shows meaningful relationships'')\n        relationship_count = 0\n        for concept in selected_concepts:\n            if concept.get(''suggested_predicates''):\n                as_subject = len(concept[''suggested_predicates''].get(''as_subject'', []))\n                as_object = len(concept[''suggested_predicates''].get(''as_object'', []))\n                relationship_count += as_subject + as_object\n                print(f''   - {concept[\"\"label\"\"]}: {as_subject + as_object} relationships'')\n        \n        print(f''\\nüéØ STEP 3: Backend processing simulation'')\n        # Import the functions we need\n        from app.routes.worlds import _generate_preview_triples, _extract_predicate_triples\n        from app.models.world import World\n        \n        world = World.query.get(1)\n        \n        # Generate basic triples\n        basic_triples = _generate_preview_triples(selected_concepts, 36, world)\n        print(f''   - Generated {len(basic_triples)} basic concept triples'')\n        \n        # Generate predicate suggestion triples  \n        predicate_triples = _extract_predicate_triples(selected_concepts, 36, world)\n        print(f''   - Generated {len(predicate_triples)} predicate suggestion triples'')\n        \n        all_triples = basic_triples + predicate_triples\n        print(f''   - Total triples to save: {len(all_triples)}'')\n        \n        print(f''\\nüìä WORKFLOW VERIFICATION:'')\n        print(f''   ‚úÖ Concepts with predicate suggestions: {len([c for c in selected_concepts if c.get(\"\"suggested_predicates\"\")])}'')\n        print(f''   ‚úÖ Meaningful relationships identified: {relationship_count}'')\n        print(f''   ‚úÖ Basic concept triples: {len(basic_triples)}'')\n        print(f''   ‚úÖ Predicate suggestion triples: {len(predicate_triples)}'')\n        print(f''   ‚úÖ Total semantic relationships: {len(all_triples)}'')\n        \n        print(f''\\nüéâ COMPLETE SUCCESS!'')\n        print(f''üåê Ready for end-to-end testing:'')\n        print(f''   1. Visit: http://localhost:3333/worlds/1/guidelines/36'')\n        print(f''   2. Click \"\"Load Pending Concepts ({len(concepts_list)})\"\"'')\n        print(f''   3. Review concepts with predicate suggestions visible'')\n        print(f''   4. Click \"\"Save Concepts to Ontology\"\"'')\n        print(f''   5. Modal shows {len(selected_concepts)} concepts, {relationship_count} relationships'')\n        print(f''   6. Confirm save ‚Üí {len(all_triples)} triples saved to ontology'')\n        print(f''   7. Advanced Triple Review still available as secondary option'')\n        \n    else:\n        print(''‚ùå No session found for testing'')\n\")",
      "Bash(ANTHROPIC_API_KEY=test SQLALCHEMY_DATABASE_URI=\"postgresql://postgres:PASS@localhost:5433/ai_ethical_dm\" python -c \"\nfrom app import create_app\nfrom app.routes.worlds import save_concepts_direct\n\nclass TestConfig:\n    SQLALCHEMY_DATABASE_URI = ''postgresql://postgres:PASS@localhost:5433/ai_ethical_dm''\n    TESTING = True\n    SECRET_KEY = ''test-key''\n\napp = create_app(TestConfig)\nwith app.app_context():\n    # Test that the imports work correctly\n    from app.services.triple_duplicate_detection_service import TripleDuplicateDetectionService\n    from app.services.guideline_concept_integration_service import GuidelineConceptIntegrationService\n    \n    print(''‚úÖ All required imports successful!'')\n    print(''‚úÖ TripleDuplicateDetectionService imported correctly'')\n    print(''‚úÖ GuidelineConceptIntegrationService imported correctly'')\n    \n    # Test instantiation\n    duplicate_service = TripleDuplicateDetectionService()\n    print(''‚úÖ TripleDuplicateDetectionService instantiated successfully'')\n    \n    # Check that the integration service method exists\n    assert hasattr(GuidelineConceptIntegrationService, ''add_concepts_to_ontology'')\n    print(''‚úÖ GuidelineConceptIntegrationService.add_concepts_to_ontology method exists'')\n    \n    print('''')\n    print(''üéâ FIXES APPLIED SUCCESSFULLY!'')\n    print(''The save_concepts_direct route should now work correctly:'')\n    print(''  1. Fixed import from guideline_triple_duplicate_service to triple_duplicate_detection_service'')\n    print(''  2. Added integration with derived ontology via GuidelineConceptIntegrationService'')\n    print(''  3. Concepts will be saved as both EntityTriples AND integrated into the derived ontology'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3 -c \"\nfrom app import create_app\nfrom app.models.document import Document\n\napp = create_app(''config'')\nwith app.app_context():\n    doc = Document.query.get(36)\n    if doc:\n        print(f''Document 36: {doc.title}'')\n        print(f''Type: {doc.document_type}'')\n        print(f''World ID: {doc.world_id}'')\n        if doc.doc_metadata:\n            print(''Metadata keys:'', list(doc.doc_metadata.keys()))\n            if ''guideline_id'' in doc.doc_metadata:\n                print(f''Guideline ID: {doc.doc_metadata[\"\"guideline_id\"\"]}'')\n            else:\n                print(''No guideline_id in metadata'')\n        else:\n            print(''No metadata'')\n    else:\n        print(''Document 36 not found'')\n\")",
      "Bash(FLASK_APP=app DATABASE_URL=postgresql://postgres:PASS@localhost:5433/ai_ethical_dm python3:*)"
    ],
    "deny": []
  }
}